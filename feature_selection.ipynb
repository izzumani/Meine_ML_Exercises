{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction to Feature Selection \n",
    "\n",
    "\n",
    "#### Feature selection\n",
    "Feature selection or variable selection is the process of selecting a subset of relevant features or variables from the total features of a level in a data set to build machine learning algorithms.\n",
    "#### Advantages of selecting features\n",
    "There are various advantages of feature selection process. These are as follows:-\n",
    "\n",
    "1. Improved accuracy\n",
    "2. Simple models are easier to interpret.\n",
    "3. Shorter training times\n",
    "4. Enhanced generalization by reducing Overfitting\n",
    "5. Easier to implement by software developers\n",
    "6. Reduced risk of data errors by model use\n",
    "7. Variable redundancy\n",
    "8. Bad learning behaviour in high dimensional spaces\n",
    "#### Feature Selection â€“ Techniques\n",
    "Feature selection techniques are categorized into 3 typers. These are as follows:-\n",
    "\n",
    "1. Filter methods\n",
    "2. Wrapper methods\n",
    "3. Embedded methods\n",
    "\n",
    "### Filter Methods\n",
    "Filter methods consists of various techniques as given below:-\n",
    "\n",
    "- Basic methods\n",
    "- Univariate methods\n",
    "- Information gain\n",
    "- Fischer score\n",
    "- Correlation Matrix with Heatmap\n",
    "\n",
    "### Wrapper Methods\n",
    "- Wrapper methods consists of the following techniques:-\n",
    "\n",
    "1. Forward Selection\n",
    "2. Backward Elimination\n",
    "3. Exhaustive Feature Selection\n",
    "4. Recursive Feature Elimination\n",
    "5. Recursive Feature Elimination with Cross-Validation\n",
    "\n",
    "### Embedded Methods\n",
    "- Embedded methods consists of the following techniques:-\n",
    "\n",
    "1. LASSO\n",
    "2. RIDGE\n",
    "3. Tree Importance\n",
    "- Now, we will discuss these methods in detail.\n",
    "\n",
    "### 2. Filter Methods \n",
    "\n",
    "\n",
    "Filter methods are generally used as a preprocessing step. The selection of features is independent of any machine learning algorithms. Instead, features are selected on the basis of their scores in various statistical tests for their correlation with the outcome variable. The characteristics of these methods are as follows:-\n",
    "\n",
    "- These methods rely on the characteristics of the data (feature characteristics)\n",
    "- They do not use machine learning algorithms.\n",
    "- These are model agnostic.\n",
    "- They tend to be less computationally expensive.\n",
    "- They usually give lower prediction performance than wrapper methods.\n",
    "- They are very well suited for a quick screen and removal of irrelevant features.\n",
    "\n",
    "- Filter methods consists of various techniques as given below:-\n",
    "\n",
    "- 2.1. Basic methods\n",
    "- 2.2. Univariate feature selection\n",
    "- 2.3. Information gain\n",
    "- 2.4. Fischer score\n",
    "- 2.5. ANOVA F-Value for Feature Selection\n",
    "- 2.6. Correlation Matrix with Heatmap\n",
    "Filter methods can be explained with the help of following graphic:\n",
    "FilterMethods\n",
    "\n",
    "Image source : AnalyticsVidhya\n",
    "2.1 Basic methods \n",
    "\n",
    "\n",
    "Under basic methods, we remove constant and quasi-constant features.\n",
    "2.1.1 Remove constant features \n",
    "Table of Contents\n",
    "\n",
    "Constant features are those that show the same value, just one value, for all the observations of the dataset. This is, the same value for all the rows of the dataset. These features provide no information that allows a machine learning model to discriminate or predict a target.\n",
    "\n",
    "Identifying and removing constant features, is an easy first step towards feature selection and more easily interpretable machine learning models. To identify constant features, we can use the VarianceThreshold function from sklearn.\n",
    "\n",
    "I will demonstrate how to identify constant features using the Santander Customer Satisfaction dataset from Kaggle.\n",
    "\n",
    "Source :\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/feature_selection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "3   8     2     37                 0.0                    195.0   \n",
       "4  10     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "3                      0.0                      0.0  ...   \n",
       "4                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('./files/Santander-Customer-Satisfaction-train.csv', nrows=35000)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('./files/Santander-Customer-Satisfaction-test.csv', nrows=15000)\n",
    "X_test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using variance threshold from sklearn\n",
    "\n",
    "Variance threshold from sklearn is a simple baseline approach to feature selection. It removes all features which variance doesnâ€™t meet some threshold. By default, it removes all zero-variance features, i.e., features that have the same value in all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sklearn variancethreshold to find constant features\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=0)\n",
    "sel.fit(X_train)  # fit finds the features with zero variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_support is a boolean vector that indicates which features are retained\n",
    "# if we sum over get_support, we get the number of features that are not constant\n",
    "sum(sel.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate way of finding non-constant features\n",
    "len(X_train.columns[sel.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the constant features\n",
    "print(\n",
    "    len([\n",
    "        x for x in X_train.columns\n",
    "        if x not in X_train.columns[sel.get_support()]\n",
    "    ]))\n",
    "\n",
    "[x for x in X_train.columns if x not in X_train.columns[sel.get_support()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that there are 51 columns / variables that are constant. This means that 51 variables show the same value, just one value, for all the observations of the training set.\n",
    "- We then use the transform function to reduce the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then drop these columns from the train and test sets\n",
    "X_train = sel.transform(X_train)\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of training and test set\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Remove quasi-constant features Â¶\n",
    "\n",
    "\n",
    "- Quasi-constant features are those that show the same value for the great majority of the observations of the dataset. In general, these features provide little if any information that allows a machine learning model to discriminate or predict a target. But there can be exceptions. So we should be careful when removing these type of features. Identifying and removing quasi-constant features, is an easy first step towards feature selection and more easily interpretable machine learning models.\n",
    "\n",
    "- To identify quasi-constant features, we can once again use the VarianceThreshold function from sklearn.\n",
    "\n",
    "- Here I will demonstrate how to identify quasi-constant features using the Santander Customer Satisfaction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "3   8     2     37                 0.0                    195.0   \n",
       "4  10     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "3                      0.0                      0.0  ...   \n",
       "4                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('./files/Santander-Customer-Satisfaction-train.csv', nrows=35000)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>29822</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>29824</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141868.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>29825</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55323.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>29827</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65211.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>29833</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59049.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "14995  29822     2     23                 0.0                      0.0   \n",
       "14996  29824     2     23                 0.0                      0.0   \n",
       "14997  29825     2     53                 0.0                      0.0   \n",
       "14998  29827     2     23                 0.0                      0.0   \n",
       "14999  29833     2     23                 0.0                      0.0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "14995                      0.0                      0.0   \n",
       "14996                      0.0                      0.0   \n",
       "14997                      0.0                      0.0   \n",
       "14998                      0.0                      0.0   \n",
       "14999                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "14995                      0.0                        0   \n",
       "14996                      0.0                        0   \n",
       "14997                      0.0                        0   \n",
       "14998                      0.0                        0   \n",
       "14999                      0.0                        0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  ...  saldo_medio_var29_ult3  \\\n",
       "14995                        0  ...                       0   \n",
       "14996                        0  ...                       0   \n",
       "14997                        0  ...                       0   \n",
       "14998                        0  ...                       0   \n",
       "14999                        0  ...                       0   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "14995                      0.0                      0.0   \n",
       "14996                      0.0                      0.0   \n",
       "14997                      0.0                      0.0   \n",
       "14998                      0.0                      0.0   \n",
       "14999                      0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "14995                     0.0                     0.0   \n",
       "14996                     0.0                     0.0   \n",
       "14997                     0.0                     0.0   \n",
       "14998                     0.0                     0.0   \n",
       "14999                     0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "14995                      0.0                      0.0   \n",
       "14996                      0.0                      0.0   \n",
       "14997                      0.0                      0.0   \n",
       "14998                      0.0                      0.0   \n",
       "14999                      0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  \n",
       "14995                     0.0                     0.0  117310.979016  \n",
       "14996                     0.0                     0.0  141868.410000  \n",
       "14997                     0.0                     0.0   55323.540000  \n",
       "14998                     0.0                     0.0   65211.420000  \n",
       "14999                     0.0                     0.0   59049.300000  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv('./files/Santander-Customer-Satisfaction-test.csv', nrows=15000)\n",
    "X_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VarianceThreshold(threshold=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;VarianceThreshold<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_selection.VarianceThreshold.html\">?<span>Documentation for VarianceThreshold</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>VarianceThreshold(threshold=0.01)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "VarianceThreshold(threshold=0.01)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=0.01)  # 0.1 indicates 99% of observations approximately\n",
    "\n",
    "sel.fit(X_train)  # fit finds the features with low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(264)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_support is a boolean vector that indicates which features \n",
    "# are retained. If we sum over get_support, we get the number\n",
    "# of features that are not quasi-constant\n",
    "sum(sel.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternative way of doing the above operation:\n",
    "len(X_train.columns[sel.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ind_var1',\n",
       " 'ind_var2_0',\n",
       " 'ind_var2',\n",
       " 'ind_var6_0',\n",
       " 'ind_var6',\n",
       " 'ind_var13_largo',\n",
       " 'ind_var13_medio_0',\n",
       " 'ind_var13_medio',\n",
       " 'ind_var14',\n",
       " 'ind_var17_0',\n",
       " 'ind_var17',\n",
       " 'ind_var18_0',\n",
       " 'ind_var18',\n",
       " 'ind_var19',\n",
       " 'ind_var20_0',\n",
       " 'ind_var20',\n",
       " 'ind_var27_0',\n",
       " 'ind_var28_0',\n",
       " 'ind_var28',\n",
       " 'ind_var27',\n",
       " 'ind_var29_0',\n",
       " 'ind_var29',\n",
       " 'ind_var30_0',\n",
       " 'ind_var31_0',\n",
       " 'ind_var31',\n",
       " 'ind_var32_cte',\n",
       " 'ind_var32_0',\n",
       " 'ind_var32',\n",
       " 'ind_var33_0',\n",
       " 'ind_var33',\n",
       " 'ind_var34_0',\n",
       " 'ind_var34',\n",
       " 'ind_var40',\n",
       " 'ind_var41',\n",
       " 'ind_var39',\n",
       " 'ind_var44_0',\n",
       " 'ind_var44',\n",
       " 'ind_var46_0',\n",
       " 'ind_var46',\n",
       " 'num_var6_0',\n",
       " 'num_var6',\n",
       " 'num_var13_medio_0',\n",
       " 'num_var13_medio',\n",
       " 'num_var18_0',\n",
       " 'num_var18',\n",
       " 'num_op_var40_hace3',\n",
       " 'num_var27_0',\n",
       " 'num_var28_0',\n",
       " 'num_var28',\n",
       " 'num_var27',\n",
       " 'num_var29_0',\n",
       " 'num_var29',\n",
       " 'num_var33',\n",
       " 'num_var34_0',\n",
       " 'num_var34',\n",
       " 'num_var41',\n",
       " 'num_var46_0',\n",
       " 'num_var46',\n",
       " 'saldo_var18',\n",
       " 'saldo_var28',\n",
       " 'saldo_var27',\n",
       " 'saldo_var34',\n",
       " 'saldo_var41',\n",
       " 'saldo_var46',\n",
       " 'delta_imp_amort_var18_1y3',\n",
       " 'delta_imp_amort_var34_1y3',\n",
       " 'delta_imp_aport_var33_1y3',\n",
       " 'delta_num_aport_var33_1y3',\n",
       " 'imp_amort_var18_hace3',\n",
       " 'imp_amort_var18_ult1',\n",
       " 'imp_amort_var34_hace3',\n",
       " 'imp_amort_var34_ult1',\n",
       " 'imp_reemb_var13_hace3',\n",
       " 'imp_reemb_var17_hace3',\n",
       " 'imp_reemb_var33_hace3',\n",
       " 'imp_trasp_var17_out_hace3',\n",
       " 'imp_trasp_var33_out_hace3',\n",
       " 'ind_var7_emit_ult1',\n",
       " 'ind_var7_recib_ult1',\n",
       " 'num_var2_0_ult1',\n",
       " 'num_var2_ult1',\n",
       " 'num_aport_var33_hace3',\n",
       " 'num_aport_var33_ult1',\n",
       " 'num_var7_emit_ult1',\n",
       " 'num_meses_var13_medio_ult3',\n",
       " 'num_meses_var17_ult3',\n",
       " 'num_meses_var29_ult3',\n",
       " 'num_meses_var33_ult3',\n",
       " 'num_meses_var44_ult3',\n",
       " 'num_reemb_var13_hace3',\n",
       " 'num_reemb_var13_ult1',\n",
       " 'num_reemb_var17_hace3',\n",
       " 'num_reemb_var17_ult1',\n",
       " 'num_reemb_var33_hace3',\n",
       " 'num_reemb_var33_ult1',\n",
       " 'num_trasp_var17_in_hace3',\n",
       " 'num_trasp_var17_in_ult1',\n",
       " 'num_trasp_var17_out_hace3',\n",
       " 'num_trasp_var17_out_ult1',\n",
       " 'num_trasp_var33_in_hace3',\n",
       " 'num_trasp_var33_in_ult1',\n",
       " 'num_trasp_var33_out_hace3',\n",
       " 'num_trasp_var33_out_ult1',\n",
       " 'num_venta_var44_hace3',\n",
       " 'saldo_var2_ult1',\n",
       " 'saldo_medio_var13_medio_hace3',\n",
       " 'saldo_medio_var29_hace3']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally we can print the quasi-constant features\n",
    "print(\n",
    "    len([\n",
    "        x for x in X_train.columns\n",
    "        if x not in X_train.columns[sel.get_support()]\n",
    "    ]))\n",
    "\n",
    "[x for x in X_train.columns if x not in X_train.columns[sel.get_support()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that 107 columns / variables are almost constant. This means that 107 variables show predominantly one value for ~99% the observations of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then remove the features from training and test set\n",
    "X_train = sel.transform(X_train)\n",
    "# X_test = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 264), (15000, 370))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of training and test set\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Univariate selection methods \n",
    "\n",
    "\n",
    "- Univariate feature selection methods works by selecting the best features based on univariate statistical tests like ANOVA. It can be seen as a preprocessing step to an estimator. Scikit-learn exposes feature selection routines as objects that implement the transform method.\n",
    "\n",
    "- The methods based on F-test estimate the degree of linear dependency between two random variables. They assume a linear relationship between the feature and the target. These methods also assume that the variables follow a Gaussian distribution.\n",
    "\n",
    "- There are 4 methods that fall under this category :-\n",
    "\n",
    "1. SelectKBest\n",
    "2. SelectPercentile\n",
    "3. SelectFpr, SelectFdr, or family wise error SelectFwe\n",
    "4. GenericUnivariateSelection\n",
    "\n",
    "Here, I will limit the discussion to SelectKBest and SelectPercentile, because these two are most commonly used in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 SelectKBest \n",
    "Table of Contents\n",
    "\n",
    "This method select features according to the k highest scores.\n",
    "\n",
    "For instance, we can perform a chi-square test to the samples to retrieve only the two best features from iris dataset as follows:\n",
    "\n",
    "Source : https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the two best features\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.7, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.1]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new[:10,:]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 SelectPercentile \n",
    "\n",
    "\n",
    "Select features according to a percentile of the highest scores.\n",
    "Source : https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "        15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "        12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "         0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "        10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 12., 13.,  5.,  0.,  0.,  0.,  0.,  0., 11., 16.,\n",
       "         9.,  0.,  0.,  0.,  0.,  3., 15., 16.,  6.,  0.,  0.,  0.,  7.,\n",
       "        15., 16., 16.,  2.,  0.,  0.,  0.,  0.,  1., 16., 16.,  3.,  0.,\n",
       "         0.,  0.,  0.,  1., 16., 16.,  6.,  0.,  0.,  0.,  0.,  1., 16.,\n",
       "        16.,  6.,  0.,  0.,  0.,  0.,  0., 11., 16., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  4., 15., 12.,  0.,  0.,  0.,  0.,  3., 16., 15.,\n",
       "        14.,  0.,  0.,  0.,  0.,  8., 13.,  8., 16.,  0.,  0.,  0.,  0.,\n",
       "         1.,  6., 15., 11.,  0.,  0.,  0.,  1.,  8., 13., 15.,  1.,  0.,\n",
       "         0.,  0.,  9., 16., 16.,  5.,  0.,  0.,  0.,  0.,  3., 13., 16.,\n",
       "        16., 11.,  5.,  0.,  0.,  0.,  0.,  3., 11., 16.,  9.,  0.],\n",
       "       [ 0.,  0.,  7., 15., 13.,  1.,  0.,  0.,  0.,  8., 13.,  6., 15.,\n",
       "         4.,  0.,  0.,  0.,  2.,  1., 13., 13.,  0.,  0.,  0.,  0.,  0.,\n",
       "         2., 15., 11.,  1.,  0.,  0.,  0.,  0.,  0.,  1., 12., 12.,  1.,\n",
       "         0.,  0.,  0.,  0.,  0.,  1., 10.,  8.,  0.,  0.,  0.,  8.,  4.,\n",
       "         5., 14.,  9.,  0.,  0.,  0.,  7., 13., 13.,  9.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1., 11.,  0.,  0.,  0.,  0.,  0.,  0.,  7.,  8.,\n",
       "         0.,  0.,  0.,  0.,  0.,  1., 13.,  6.,  2.,  2.,  0.,  0.,  0.,\n",
       "         7., 15.,  0.,  9.,  8.,  0.,  0.,  5., 16., 10.,  0., 16.,  6.,\n",
       "         0.,  0.,  4., 15., 16., 13., 16.,  1.,  0.,  0.,  0.,  0.,  3.,\n",
       "        15., 10.,  0.,  0.,  0.,  0.,  0.,  2., 16.,  4.,  0.,  0.],\n",
       "       [ 0.,  0., 12., 10.,  0.,  0.,  0.,  0.,  0.,  0., 14., 16., 16.,\n",
       "        14.,  0.,  0.,  0.,  0., 13., 16., 15., 10.,  1.,  0.,  0.,  0.,\n",
       "        11., 16., 16.,  7.,  0.,  0.,  0.,  0.,  0.,  4.,  7., 16.,  7.,\n",
       "         0.,  0.,  0.,  0.,  0.,  4., 16.,  9.,  0.,  0.,  0.,  5.,  4.,\n",
       "        12., 16.,  4.,  0.,  0.,  0.,  9., 16., 16., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 12., 13.,  0.,  0.,  0.,  0.,  0.,  5., 16.,  8.,\n",
       "         0.,  0.,  0.,  0.,  0., 13., 16.,  3.,  0.,  0.,  0.,  0.,  0.,\n",
       "        14., 13.,  0.,  0.,  0.,  0.,  0.,  0., 15., 12.,  7.,  2.,  0.,\n",
       "         0.,  0.,  0., 13., 16., 13., 16.,  3.,  0.,  0.,  0.,  7., 16.,\n",
       "        11., 15.,  8.,  0.,  0.,  0.,  1.,  9., 15., 11.,  3.,  0.],\n",
       "       [ 0.,  0.,  7.,  8., 13., 16., 15.,  1.,  0.,  0.,  7.,  7.,  4.,\n",
       "        11., 12.,  0.,  0.,  0.,  0.,  0.,  8., 13.,  1.,  0.,  0.,  4.,\n",
       "         8.,  8., 15., 15.,  6.,  0.,  0.,  2., 11., 15., 15.,  4.,  0.,\n",
       "         0.,  0.,  0.,  0., 16.,  5.,  0.,  0.,  0.,  0.,  0.,  9., 15.,\n",
       "         1.,  0.,  0.,  0.,  0.,  0., 13.,  5.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  9., 14.,  8.,  1.,  0.,  0.,  0.,  0., 12., 14., 14.,\n",
       "        12.,  0.,  0.,  0.,  0.,  9., 10.,  0., 15.,  4.,  0.,  0.,  0.,\n",
       "         3., 16., 12., 14.,  2.,  0.,  0.,  0.,  4., 16., 16.,  2.,  0.,\n",
       "         0.,  0.,  3., 16.,  8., 10., 13.,  2.,  0.,  0.,  1., 15.,  1.,\n",
       "         3., 16.,  8.,  0.,  0.,  0., 11., 16., 15., 11.,  1.,  0.],\n",
       "       [ 0.,  0., 11., 12.,  0.,  0.,  0.,  0.,  0.,  2., 16., 16., 16.,\n",
       "        13.,  0.,  0.,  0.,  3., 16., 12., 10., 14.,  0.,  0.,  0.,  1.,\n",
       "        16.,  1., 12., 15.,  0.,  0.,  0.,  0., 13., 16.,  9., 15.,  2.,\n",
       "         0.,  0.,  0.,  0.,  3.,  0.,  9., 11.,  0.,  0.,  0.,  0.,  0.,\n",
       "         9., 15.,  4.,  0.,  0.,  0.,  9., 12., 13.,  3.,  0.,  0.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10,:]    \n",
    "# We can see that only 7 features lie on the top 10 percentile and hence we select them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 7)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now select features based on top 10 percentile\n",
    "X_new = SelectPercentile(chi2, percentile=10).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.,  5.,  8., 11.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  1., 16.,  0.,  0.],\n",
       "       [ 0.,  1.,  8., 16., 16.,  5.,  9.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  9.,  0.],\n",
       "       [ 8.,  5., 16., 15., 16.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  4.,  0.],\n",
       "       [ 0.,  0., 15., 13., 16.,  8.,  3.],\n",
       "       [ 6.,  2., 11.,  0., 16.,  0.,  0.],\n",
       "       [ 2.,  0.,  4., 16.,  8.,  8.,  1.],\n",
       "       [ 0.,  0., 13.,  0.,  3.,  4.,  0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important information\n",
    "- These objects take as input a scoring function that returns univariate scores and p-values (or only scores for SelectKBest and SelectPercentile:\n",
    "- For regression tasks: f_regression, mutual_info_regression\n",
    "\n",
    "- For classification tasks: chi2, f_classif, mutual_info_classif\n",
    "\n",
    "The methods based on F-test estimate the degree of linear dependency between two random variables. On the other hand, mutual information methods can capture any kind of statistical dependency, but being nonparametric, they require more samples for accurate estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection with sparse data\n",
    "If you use sparse data (i.e. data represented as sparse matrices), chi2, mutual_info_regression, mutual_info_classif will deal with the data without making it dense.\n",
    "Source : https://scikit-learn.org/stable/modules/feature_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning\n",
    "Beware not to use a regression scoring function with a classification problem, you will get useless results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Information Gain \n",
    "\n",
    "\n",
    "- Information gain or mutual information measures how much information the presence/absence of a feature contributes to making the correct prediction on the target.\n",
    "- In terms of wikipedia:\n",
    "- Mutual information measures the information that X and Y share: It measures how much knowing one of these variables reduces uncertainty about the other. For example, if X and Y are independent, then knowing X does not give any information about Y and vice versa, so their mutual information is zero. At the other extreme, if X is a deterministic function of Y and Y is a deterministic function of X then all information conveyed by X is shared with Y: knowing X determines the value of Y and vice versa. As a result, in this case the mutual information is the same as the uncertainty contained in Y (or X) alone, namely the entropy of Y (or X). Moreover, this mutual information is the same as the entropy of X and as the entropy of Y. (A very special case of this is when X and Y are the same random variable.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mutual_info_classif\n",
    "It estimates mutual information for a discrete target variable.\n",
    "\n",
    "Mutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
    "\n",
    "This function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances.\n",
    "\n",
    "It can be used for univariate features selection.\n",
    "\n",
    "Source :\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mutual_info_regression\n",
    "Estimate mutual information for a continuous target variable.\n",
    "\n",
    "Mutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
    "\n",
    "The function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances.\n",
    "\n",
    "It can be used for univariate features selection\n",
    "\n",
    "Source :\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html#sklearn.feature_selection.mutual_info_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Fisher Score (chi-square implementation)\n",
    "Table of Contents\n",
    "\n",
    "It is the chi-square implementation in scikit-learn. It computes chi-squared stats between each non-negative feature and class.\n",
    "\n",
    "This score should be used to evaluate categorical variables in a classification task. It compares the observed distribution of the different classes of target Y among the different categories of the feature, against the expected distribution of the target classes, regardless of the feature categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "# load iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# create features and target\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# convert to categorical data by converting data to integers\n",
    "X = X.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Chi-Squared Statistics\n",
    "# select two features with highest chi-squared statistics\n",
    "chi2_selector = SelectKBest(chi2, k=2)\n",
    "X_kbest = chi2_selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "# View results\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 ANOVA F-value For Feature Selection Â¶\n",
    "Table of Contents\n",
    "\n",
    "- Compute the ANOVA F-value for the provided sample.\n",
    "\n",
    "- If the features are categorical, we will calculate a chi-square statistic between each feature and the target vector. However, if the features are quantitative, we will compute the ANOVA F-value between each feature and the target vector.\n",
    "\n",
    "- The F-value scores examine if, when we group the numerical feature by the target vector, the means for each group are significantly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# Create features and target\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Features With Best ANOVA F-Values\n",
    "\n",
    "# Create an SelectKBest object to select features with two best ANOVA F-Values\n",
    "fvalue_selector = SelectKBest(f_classif, k=2)\n",
    "\n",
    "# Apply the SelectKBest object to the features and target\n",
    "X_kbest = fvalue_selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "# View results\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_kbest.shape[1])\n",
    "# We can see that the above code helps us to select the 2 best features based on ANOVA F-Value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Correlation-Matrix with Heatmap \n",
    "Table of Contents\n",
    "\n",
    "- Correlation is a measure of the linear relationship of 2 or more variables. Through correlation, we can predict one variable from the other.\n",
    "\n",
    "- Good variables are highly correlated with the target.\n",
    "\n",
    "- Correlated predictor variables provide redundant information.\n",
    "\n",
    "- Variables should be correlated with the target but uncorrelated among themselves.\n",
    "\n",
    "- Correlation Feature Selection evaluates subsets of features on the basis of the following hypothesis:\n",
    "\n",
    "    - \"Good feature subsets contain features highly correlated with the target, yet uncorrelated to each other\".\n",
    "\n",
    "\n",
    "- In this section, I will demonstrate how to select features based on correlation between two features. We can find features that are correlated with each other. By identifying these features, we can then decide which features we want to keep, and which ones we want to remove.\n",
    "\n",
    "- Using Pearson correlation our returned coefficient values will vary between -1 and 1.\n",
    "\n",
    "- If the correlation between two features is 0 this means that changing any of these two features will not affect the other.\n",
    "\n",
    "- If the correlation between two features is greater than 0 this means that increasing the values in one feature will make increase also the values in the other feature (the closer the correlation coefficient is to 1 and the stronger is going to be this bond between the two different features).\n",
    "\n",
    "- If the correlation between two features is less than 0 this means that increasing the values in one feature will make decrease the values in the other feature (the closer the correlation coefficient is to -1 and the stronger is going to be this relationship between the two different features).\n",
    "\n",
    "- In this analysis we will check if the selected variables are highly correlated with each other. If they are, we would then need to keep just one of the correlated ones and drop the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris data\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Create features and target\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3\n",
      "0    5.1  3.5  1.4  0.2\n",
      "1    4.9  3.0  1.4  0.2\n",
      "2    4.7  3.2  1.3  0.2\n",
      "3    4.6  3.1  1.5  0.2\n",
      "4    5.0  3.6  1.4  0.2\n",
      "..   ...  ...  ...  ...\n",
      "145  6.7  3.0  5.2  2.3\n",
      "146  6.3  2.5  5.0  1.9\n",
      "147  6.5  3.0  5.2  2.0\n",
      "148  6.2  3.4  5.4  2.3\n",
      "149  5.9  3.0  5.1  1.8\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert feature matrix into DataFrame\n",
    "df = pd.DataFrame(X)\n",
    "\n",
    "# View the data frame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3\n",
      "0  1.000000 -0.117570  0.871754  0.817941\n",
      "1 -0.117570  1.000000 -0.428440 -0.366126\n",
      "2  0.871754 -0.428440  1.000000  0.962865\n",
      "3  0.817941 -0.366126  0.962865  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAISCAYAAAD7kgrVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABqa0lEQVR4nO3dd1gUVxcG8HeXsghIUQRERYpGrKAo9qgRS8SCsTewm8QaTFSM3US+WDHG3qMx1misWEBjCYINjQUVewNEepG28/1hWF1ZDCM7Unx/eeZ5snfvzJzZXeFw7p27MkEQBBARERGRJOSFHQARERFRScZki4iIiEhCTLaIiIiIJMRki4iIiEhCTLaIiIiIJMRki4iIiEhCTLaIiIiIJMRki4iIiEhCTLaIiIiIJMRki4qUDRs2QCaT4f79+1o75v379yGTybBhwwatHZOKpuTkZAwdOhTW1taQyWQYN26cVo7LzxARFQSTrY/AnTt3MGLECDg4OMDAwAAmJiZo2rQpFi9ejLS0tMIOT2u2bNkCf3//wg5DzcCBA2FsbJzn8zKZDKNGjZI0hmXLln00ScKcOXOwYcMGfPXVV9i0aRMGDBiQZ187Ozt07NjxA0b3yowZMyCTyVSboaEhbG1t0alTJ6xfvx7p6envfeyDBw9ixowZ2gu2gObMmYM9e/YUdhhEhU63sAMgaR04cAA9evSAQqGAl5cXatWqhYyMDJw+fRrfffcdrl27hlWrVhV2mFqxZcsWXL16NVc1o3LlykhLS4Oenl7hBFbIli1bBgsLCwwcOLCwQ5FcUFAQGjVqhOnTp2v1uFJ8hpYvXw5jY2Okp6fjyZMnOHz4MAYPHgx/f3/s378flSpVEn3MgwcPYunSpUUm4ZozZw66d+8OT0/Pwg6FqFAx2SrB7t27h969e6Ny5coICgpC+fLlVc+NHDkSEREROHDgQIHPIwgCXr58iVKlSuV67uXLl9DX14dcXnhFVJlMBgMDg0I7P3040dHRqFGjhtaOl5WVBaVSCX19fa1/hrp37w4LCwvV42nTpuG3336Dl5cXevTogbNnz2r1fERUeDiMWILNnTsXycnJWLt2rVqilaNKlSoYO3as6nFWVhZmz54NR0dHKBQK2NnZYfLkybmGNXKGXw4fPoz69eujVKlSWLlyJU6cOAGZTIatW7diypQpqFChAgwNDZGYmAgACAkJQfv27WFqagpDQ0O0aNECZ86c+c/r+PPPP+Hh4QEbGxsoFAo4Ojpi9uzZyM7OVvVp2bIlDhw4gAcPHqiGZ+zs7ADkPd8mKCgIzZs3h5GREczMzNClSxfcuHFDrU/OkE9ERAQGDhwIMzMzmJqaYtCgQUhNTf3P2N9Heno6pk+fjipVqkChUKBSpUqYMGFCrvdh/fr1+Oyzz2BpaQmFQoEaNWpg+fLlan3s7Oxw7do1/PXXX6rXpWXLlgBez487ffo0xowZg3LlysHMzAwjRoxARkYG4uPj4eXlBXNzc5ibm2PChAkQBEHt+PPnz0eTJk1QtmxZlCpVCq6urti5c2eua8oZLv3tt99QrVo1GBgYwNXVFSdPnszXaxIdHY0hQ4bAysoKBgYGcHZ2xsaNG1XP53z27t27hwMHDqiuVczcv5zPyfz58+Hv76/6d3D9+nWNn6HIyEgMGjQIFStWhEKhQPny5dGlS5cCzTfs168fhg4dipCQEBw9elTVfurUKfTo0QO2traqz8Q333yjNg1g4MCBWLp0KQCoDVPmyO97dfToUTRr1gxmZmYwNjZGtWrVMHnyZLU++fmMymQypKSkYOPGjapYPobqKpEmrGyVYPv27YODgwOaNGmSr/5Dhw7Fxo0b0b17d4wfPx4hISHw8/PDjRs3sHv3brW+N2/eRJ8+fTBixAgMGzYM1apVUz03e/Zs6Ovr49tvv0V6ejr09fURFBSEzz//HK6urpg+fTrkcrkqWTh16hTc3NzyjGvDhg0wNjaGj48PjI2NERQUhGnTpiExMRHz5s0DAHz//fdISEjA48ePsWjRIgB451ypY8eO4fPPP4eDgwNmzJiBtLQ0LFmyBE2bNsXFixdViVqOnj17wt7eHn5+frh48SLWrFkDS0tL/PTTT/l6bWNiYvLVT6lUonPnzjh9+jSGDx+O6tWr459//sGiRYtw69Yttfkvy5cvR82aNdG5c2fo6upi3759+Prrr6FUKjFy5EgAgL+/P0aPHg1jY2N8//33AAArKyu1c44ePRrW1taYOXMmzp49i1WrVsHMzAx///03bG1tMWfOHBw8eBDz5s1DrVq14OXlpdp38eLF6Ny5M/r164eMjAxs3boVPXr0wP79++Hh4aF2nr/++gvbtm3DmDFjoFAosGzZMrRv3x6hoaGoVatWnq9JWloaWrZsiYiICIwaNQr29vbYsWMHBg4ciPj4eIwdOxbVq1fHpk2b8M0336BixYoYP348AKBcuXL5et3ftH79erx8+RLDhw+HQqFAmTJloFQqc/Xr1q0brl27htGjR8POzg7R0dE4evQoHj58mOvzI8aAAQOwatUqHDlyBG3atAEA7NixA6mpqfjqq69QtmxZhIaGYsmSJXj8+DF27NgBABgxYgSePn2Ko0ePYtOmTbmOm5/36tq1a+jYsSPq1KmDWbNmQaFQICIiQu2Povx+Rjdt2oShQ4fCzc0Nw4cPBwA4Ojq+9+tCVKwJVCIlJCQIAIQuXbrkq39YWJgAQBg6dKha+7fffisAEIKCglRtlStXFgAIAQEBan2PHz8uABAcHByE1NRUVbtSqRSqVq0qtGvXTlAqlar21NRUwd7eXmjTpo2qbf369QIA4d69e2r93jZixAjB0NBQePnyparNw8NDqFy5cq6+9+7dEwAI69evV7W5uLgIlpaWwosXL1Rtly9fFuRyueDl5aVqmz59ugBAGDx4sNoxu3btKpQtWzbXud7m7e0tAHjnNnLkSFX/TZs2CXK5XDh16pTacVasWCEAEM6cOfPO16Vdu3aCg4ODWlvNmjWFFi1a5Oqb81q//b40btxYkMlkwpdffqlqy8rKEipWrJjrOG/HkJGRIdSqVUv47LPP1NpzrvX8+fOqtgcPHggGBgZC165dc8X2Jn9/fwGAsHnzZrXzNG7cWDA2NhYSExNV7ZUrVxY8PDzeeby8+uZ8TkxMTITo6Gi1vm9/huLi4gQAwrx58/J1rjflfKaeP3+u8fmcY7/5umh6r/38/ASZTCY8ePBA1TZy5Eghrx/r+XmvFi1a9M7YBEHcZ9TIyEjw9vbO81hEHwsOI5ZQOUN3pUuXzlf/gwcPAgB8fHzU2nMqBG/P7bK3t0e7du00Hsvb21tt/lZYWBhu376Nvn374sWLF4iJiUFMTAxSUlLQunVrnDx5UmPlIMebx0pKSkJMTAyaN2+O1NRUhIeH5+v63vTs2TOEhYVh4MCBKFOmjKq9Tp06aNOmjeq1eNOXX36p9rh58+Z48eKF6nV+FwMDAxw9elTj9rYdO3agevXqcHJyUr1OMTEx+OyzzwAAx48fV/V983VJSEhATEwMWrRogbt37yIhIeG/X4h/DRkyRG24qWHDhhAEAUOGDFG16ejooH79+rh7967avm/GEBcXh4SEBDRv3hwXL17MdZ7GjRvD1dVV9djW1hZdunTB4cOH1YaE33bw4EFYW1ujT58+qjY9PT2MGTMGycnJ+Ouvv/J9rfnRrVu3/6yIlSpVCvr6+jhx4gTi4uK0ev6cimxSUpLa+XKkpKQgJiYGTZo0gSAIuHTpUr6Om5/3yszMDMCrofu8/k2K+YwS0SscRiyhTExMAKj/wH6XBw8eQC6Xo0qVKmrt1tbWMDMzw4MHD9Ta7e3t8zzW28/dvn0bwKskLC8JCQkwNzfX+Ny1a9cwZcoUBAUF5UpuxCQVOXKu5c2hzxzVq1fH4cOHkZKSAiMjI1W7ra2tWr+cWOPi4lSvdV50dHTg7u6er9hu376NGzdu5PnLPjo6WvX/Z86cwfTp0xEcHJxr/lhCQgJMTU3zdc63ry1nv7fvhjM1Nc2VWOzfvx8//PADwsLCcs3XeVvVqlVztX3yySdITU3F8+fPYW1trTG+Bw8eoGrVqrlusqhevbrqeW1612c7h0KhwE8//YTx48fDysoKjRo1QseOHeHl5ZXndeRXcnIyAPU/lB4+fIhp06Zh7969ud6D/P4byM971atXL6xZswZDhw7FpEmT0Lp1a3zxxRfo3r276vUX8xkloleYbJVQJiYmsLGxwdWrV0Xtp+mXpCaa7jzM67mcv5DnzZsHFxcXjfvkNb8qPj4eLVq0gImJCWbNmgVHR0cYGBjg4sWLmDhx4jsrYtqko6OjsV14a8J4QSmVStSuXRsLFy7U+HxOAnTnzh20bt0aTk5OWLhwISpVqgR9fX0cPHgQixYtEvW65HVtmtrfvN5Tp06hc+fO+PTTT7Fs2TKUL18eenp6WL9+PbZs2ZLv8xc17/psv2ncuHHo1KkT9uzZg8OHD2Pq1Knw8/NDUFAQ6tat+97nz/k3m/OHT3Z2Ntq0aYPY2FhMnDgRTk5OMDIywpMnTzBw4MB8vdf5fa9KlSqFkydP4vjx4zhw4AACAgKwbds2fPbZZzhy5Ah0dHTy/RkloteYbJVgHTt2xKpVqxAcHIzGjRu/s2/lypWhVCpx+/ZtVcUAAKKiohAfH4/KlSu/dxw5k2JNTEzyXeHJceLECbx48QJ//PEHPv30U1X7vXv3cvXNb6KYcy03b97M9Vx4eDgsLCzUqlofkqOjIy5fvozWrVu/83r27duH9PR07N27V60ypWkIJ7+vi1i7du2CgYEBDh8+DIVCoWpfv369xv45Fc433bp1C4aGhu8ctqtcuTKuXLkCpVKpVt3KGUIuyGezoBwdHTF+/HiMHz8et2/fhouLCxYsWIDNmze/9zFzJrfnDNP/888/uHXrFjZu3Kh2c4KmYei83msx75VcLkfr1q3RunVrLFy4EHPmzMH333+P48ePw93dPd+f0XfFQ/Sx4ZytEmzChAkwMjLC0KFDERUVlev5O3fuYPHixQCADh06AECuFdhz/np9+84yMVxdXeHo6Ij58+erhkje9Pz58zz3zamuvFlRycjIwLJly3L1NTIyyteQSvny5eHi4oKNGzciPj5e1X716lUcOXJE9VoUhp49e+LJkydYvXp1rufS0tKQkpICQPPrkpCQoPGXp5GRkdp1aouOjg5kMpnafKv79+/nuWJ4cHCw2vygR48e4c8//0Tbtm3zrK4Brz6bkZGR2LZtm6otKysLS5YsgbGxMVq0aFHwixEpNTUVL1++VGtzdHRE6dKlC7QC/JYtW7BmzRo0btwYrVu3BqD5vRYEQfVv9005fyS8/X7n972KjY3NdcycanTOdeX3M5oTjxSfPaLihpWtEszR0RFbtmxBr169UL16dbUV5P/++2/V7fMA4OzsDG9vb6xatUo1dBcaGoqNGzfC09MTrVq1eu845HI51qxZg88//xw1a9bEoEGDUKFCBTx58gTHjx+HiYkJ9u3bp3HfJk2awNzcHN7e3hgzZgxkMhk2bdqkcfjO1dUV27Ztg4+PDxo0aABjY2N06tRJ43HnzZuHzz//HI0bN8aQIUNUSz+YmpoW6urbAwYMwPbt2/Hll1/i+PHjaNq0KbKzsxEeHo7t27er1jZr27Yt9PX10alTJ4wYMQLJyclYvXo1LC0t8ezZM7Vjurq6Yvny5fjhhx9QpUoVWFpaqiYzF4SHhwcWLlyI9u3bo2/fvoiOjsbSpUtRpUoVXLlyJVf/WrVqoV27dmpLPwDAzJkz33me4cOHY+XKlRg4cCAuXLgAOzs77Ny5E2fOnIG/v3++bwLRplu3bqF169bo2bMnatSoAV1dXezevRtRUVHo3bt3vo6xc+dOGBsbIyMjQ7WC/JkzZ+Ds7KxazgEAnJyc4OjoiG+//RZPnjyBiYkJdu3apXFifs4NCGPGjEG7du2go6OD3r175/u9mjVrFk6ePAkPDw9UrlwZ0dHRWLZsGSpWrIhmzZoByP9nNCeeY8eOYeHChbCxsYG9vT0aNmz43q87UbFVaPdB0gdz69YtYdiwYYKdnZ2gr68vlC5dWmjatKmwZMkStaUTMjMzhZkzZwr29vaCnp6eUKlSJcHX11etjyDkfXt9ztIPO3bs0BjHpUuXhC+++EIoW7asoFAohMqVKws9e/YUAgMDVX00Lf1w5swZoVGjRkKpUqUEGxsbYcKECcLhw4cFAMLx48dV/ZKTk4W+ffsKZmZmAgDVMhCaln4QBEE4duyY0LRpU6FUqVKCiYmJ0KlTJ+H69etqffK6TV9TnJp4e3sLRkZGeT6Pt5Z+EIRXt+T/9NNPQs2aNQWFQiGYm5sLrq6uwsyZM4WEhARVv7179wp16tQRDAwMBDs7O+Gnn34S1q1blyuuyMhIwcPDQyhdurQAQLV8Q841nDt3Ll/XrOla1q5dK1StWlVQKBSCk5OTsH79etX+mq5z8+bNqv5169ZVe//eJSoqShg0aJBgYWEh6OvrC7Vr1871fgqCdpZ+0LScw9ufoZiYGGHkyJGCk5OTYGRkJJiamgoNGzYUtm/f/p/nzXl9cjYDAwOhYsWKQseOHYV169bl+vcmCIJw/fp1wd3dXTA2NhYsLCyEYcOGCZcvX871uc7KyhJGjx4tlCtXTpDJZGrvQ37eq8DAQKFLly6CjY2NoK+vL9jY2Ah9+vQRbt26pRZPfj+j4eHhwqeffiqUKlVKAMBlIOijJRMELc/wJSJ6i0wmw8iRI/HLL78UdihERB8c52wRERERSYjJFhEREZGEmGwRERERSYjJFhFJThAEztciIkmcPHkSnTp1go2NDWQyWZ7Lz7zpxIkTqFevHhQKBapUqYINGzZIGiOTLSIiIiq2UlJS4OzsjKVLl+ar/7179+Dh4YFWrVohLCwM48aNw9ChQ3H48GHJYuTdiERERFQiyGQy7N69G56ennn2mThxIg4cOKD2dXa9e/dGfHw8AgICJImLlS0iIiIqUtLT05GYmKi2FeTbGd4UHByc66vj2rVrh+DgYK0cX5Mis4J8Zszdwg6BtKiP67jCDoG0ZPNO78IOgbRISMj767GoeCnl/mWhnVvq39l+v/ya69slpk+frpVv+IiMjISVlZVam5WVFRITE5GWlpbvL6MXo8gkW0REREQA4OvrCx8fH7W2N79EvbhhskVERETiKLP/u08BKBQKyZIra2trREVFqbVFRUXBxMREkqoWwGSLiIiIxBKUhR3Be2vcuDEOHjyo1nb06FE0btxYsnNygjwREREVW8nJyQgLC0NYWBiAV0s7hIWF4eHDhwBeDUl6eXmp+n/55Ze4e/cuJkyYgPDwcCxbtgzbt2/HN998I1mMrGwRERGROMqiU9k6f/48WrVqpXqcM9fL29sbGzZswLNnz1SJFwDY29vjwIED+Oabb7B48WJUrFgRa9asQbt27SSLkckWERERFVstW7bEu5YM1bQ6fMuWLXHp0iUJo1LHZIuIiIhEEYrxnK3CwDlbRERERBJiZYuIiIjEKUJztooDVraIiIiIJMTKFhEREYnDOVuiMNkiIiIicSReQb6k4TAiERERkYRY2SIiIiJxOIwoCitbRERERBJiZYuIiIjE4dIPorCyRURERCQhVraIiIhIFH5djzisbBERERFJiJUtIiIiEodztkRhskVERETicBhRFA4jEhEREUmIlS0iIiISh1/XIworW0REREQSYmWLiIiIxOGcLVFY2SIiIiKSECtbREREJA6XfhCFlS0iIiIiCbGyRUREROJwzpYoTLaIiIhIHA4jisJhRCIiIiIJsbJFREREoggCFzUVg5UtIiIiIgmxskVERETicIK8KKxsEREREUmIlS0iIiISh3cjisLKFhEREZGEWNkiIiIicThnSxQmW0RERCSOkks/iMFhRCIiIiIJsbJFRERE4nAYURRWtoiIiIgkxMoWERERicOlH0RhZYuIiIhIQqxsERERkTicsyUKK1tEREREEmJli4iIiMThnC1RmGwRERGROEy2ROEwIhEREZGEWNkiIiIiUQSBX9cjBitbRERERBIqUGUrODgYdnZ2KF++vLbiKTbOh/2D9Vt24np4BJ6/iMViv6lo/WmTd+4TevEK5i1ZhYh7D2BtWQ4jvPvA06ONWp/fd+3D+i07ERMbh2pVHDD5m69Qu0Y1KS+F3tDLpy/c+7SFoYkRbp6/gVXfL0fk/Wd59q/uVhNdRnSFQ21HlLEqi5+G/YhzR0JUz+vo6qDPt/1Rt5UrrGytkZqUgn9OX8bm//2KuOjYD3FJH62tR4Ox8cApxCQk4xNba0zy6oTajpXy7L854Ay2HwtB5It4mJU2Qhu3WhjTsy0U+noAgM/HzcXTmPhc+/Vyb4jJA7tIdRkEYOtfYdh47AJeJKbgkwrlMLFnK9S2s86z/+agi9hx6goi4xJhZlQK7nWrYkyXZlDovfqVt/ZwKALDInA/KhYKPV04O9hgnGcz2FmV+VCXVPxxzpYo71XZCgwMhIODA/r06QM3NzcMGzYMUVFR2o6tSEtLe4lqVRzw/fiv89X/8dNIjPxuGtzqOWPnhqUY0NMT03/yx5mQC6o+h479hblLVuGrwf2wY90SVKtijxE+U/AiLl6iq6A3eX75BToM7IhVk5djcpfvkJ6ajqmbZkJPoZfnPgaGCty/cQ9rpq7U+LyilAL2tRyx8+dtmODxDeaN+B9sHCpg0trvpboMAhBw9grm/3YQI7q2xtYfRqKabXl89dN6vEhI1tj/4N9hWLztML784jPsnvsNZgz7AofPXsHP24+o+vw262sE/uKr2lZOGgwAaONW+4Nc08fq8IWbWPDHSYzo0Ai/T+qHTypa4Otf/kBsUqrG/gfPhePnP09jRIdG+GOqN6b3b4sjF29hyd4zqj4Xbj9Gr0+d8eu3vbFidDdkZSvx1ZI/kJae+aEuiz4yopOtR48eYcqUKejfvz8CAwOxaNEiBAUFYeTIkcjIyJAixiKpeeMGGDPcG+4tmuar//Y9B1ChvDW+Gz0Mjna26Nu9M9q0bIZft+1W9fl122507/Q5unq0haN9ZUz7bjQMFArs3n/kHUcmbfEY0hm7ftmOc0dD8CD8Ppb4LIK5ZRm4tW2U5z6XTlzE1vm/IfTwWY3PpyalYnb/aQg+cAZP7z7B7Us3sWbaSjjWqQoLGwupLuWjt+nQaXzRqgE8W7jCsYIVpgzqAgOFPvb8dUFj/7DbD+FS1RYdmrigQjlzNKldFe0bO+Pq3ceqPmVMjGFhVlq1nbwUjkqWZVC/uv2HuqyP0qbAi/iiSS14Nq4Jx/JlMaW3Owz0dbEn+KrG/pfvPoWLgw06NHBChbKmaFK9Mtq7VsPV+5GqPstGfYEujWuiio0FqlUsh1kD2uJZXBKuP/y4igYFIiil3UoY0clWeHg4Ll++DG9vbzg6OqJ79+6YO3cunj9/jiVLlkgRY4lw+Wo4GtV3UWtr2tAVl6/eAABkZmbi+s3baNTgdR+5XI5G9V1UfUg6lpWsYG5ZBldOX1a1pSal4nbYLXxST7vDuIaljaBUKpGSmKLV49IrmVlZuHHvKRrVrKJqk8vlaFTTEVciHmrcx6WqLW7cf4p/7jwCADyOjsXpyzfR3Fnze5+ZlYUDZ8Lg2aI+ZDKZ9i+CAACZWdm48SgKDZ1sVW1yuQwNnWxx5a7m4X1nBxtcfxSNf/5Nrh7HxOP0tftoVjPvpDg57VWhwNTIQIvRE70mes5WbGwsqlevjuzs13cieHp6Ijw8HOvWrYOXlxfKlSv3zmOkp6cjPT1drU2eng6FQiE2nGIjJjYOZcuYq7WVNTdDckoqXqanIzExGdnZytx9ypjj3sPHIGmZW7563ePfmpOTEBMPs3LmGvZ4P3oKPfT39caZvSeRlpymtePSa3FJqchWKlHW1FitvaypMe49e65xnw5NXBCXlIqBs1YBEJCVrUSP1m4Y2qWlxv5B568jKfUlOn9aT8vR05viktOQrRRQtrShWnvZ0oa4HxmncZ8ODZwQn5yGQQu3AQKQpVSiR7M6GNreTWN/pVLAvF0n4OJggyqsNucf52yJIrqyVbNmTVy/fh3h4eGqNh0dHXh4eKBSpUpYsWLFfx7Dz88PpqamattPi/97PyJtae7ZApuub1NtOro6kp9TR1cHPksnQCaTYdX3yyU/H+Xfuet3sXbvCXw/sDO2/jAKC8f2w6mwm1i5O0hj/91/XUBT509gaW7ygSOl/3Lu1iOsPRyKyb0+w++T+mHhsE44de0eVh3SPNTvty0IEU9f4KfBHT5wpMUchxFFEV3ZqlWrFlq1aoWFCxfis88+g7Hxq78eXVxcYGlpifPnz0MQhHeW1n19feHj46PWJk96IjaUYsWijDlexKr/JfYiLh7GRoYwUCigYyaHjo48d5/YOFiU0V5lhV45dzQUty/dUj3W1X/1T8HMwgzx0a/fA1MLM9y/frfA58tJtMpVsMSMPlNY1ZKQeWlD6MjluSbDv0hIhoVpaY37LN15FB2b1sUXrRoAAKpWskZaegZmr9uDYV1aQi5//Xfp05g4hFyNwMJx/aS7CAIAmBuXgo5chhdvTYZ/kZQKCxNDjfss2/83PNyq44umr25cqFrBAmkZmZi95RiGtmsIufz17ya/bUE4efUu1n3TE1bmmj8bRNrwXncj+vn54cyZM9i8ebPapHhbW1tcv379P+cwKBQKmJiYqG0leQgRAJxrOSHkwmW1tuBzl+BcqzoAQE9PDzWqVUXI+TDV80qlEiEXwlR9SHtepqQh8sEz1fb49iPERceidlNnVZ9SxqVQ1eUT3Lp4s0Dnykm0ytvbYFa/qUiOTypo+PQOerq6qG5vg5BrEao2pVKJkGt3UKeKrcZ9XmZkQiZX/7ml82+CJbzV98+/LqCMiTGau3BJFqnp6eqgeiUrhN58pGpTKgWE3nyEOg6alxx6mZGlllABUD0W/n03BUGA37YgBF2OwKqx3VHBwlSiKyjBlEpptxLmvdbZcnZ2xsSJEzF79mzo6emhd+/eUCqVOH/+PPr376/tGIuk1NQ0PHz8VPX4ydMohN+6A1OT0ihvbYlFy9cjOuYF/KZ+CwDo6emB33ftw4Kla9G1Y1uEXriMw0EnsWzeLNUxvHp1xfc/LkBNp6qoVaMaNm/fg7SX6bnW4iJpHFi7F91G98Sze08R/SgKvcf3Q1x0LEKPvB5+mL5lNkIOn0XAxgMAAANDA1jbvf6hb1XJCnY17JEcn4SYpzHQ0dXBt8snwb6WA/wGz4ZcRw6zcmYAgOT4ZGRlZn3Qa/xYDPi8Gaau3Ima9hVRy7EiNgecQVp6BjxbvJpj9f2KHbA0N8HYXu0AAC3qOmHToTNwqlwetR0r4VHUCyzdeRSf1nVSJV3Aq6Ttz5MX0al5XejqSD/0TMCA1vUw9dfDqGFriVp21vgt6BLS0jPRpVFNAMCUjQGwNDPGmC7NAACf1nbA5qCLcKpoidp21nj4PB7L9v2NT2s7qN7LOduCcOj8TfiP6AwjhT5iEl7drGJcSgEDfX6xCmnfe3+qfvjhB8TFxWHq1KlYvXo1IiMjYWRkhIULF2ozviLravhtDB49UfV47pJVAIAun7vjxynjEfMiFs+iolXPV7SxxtJ5szD355XYvGMPrMpZYObEcWja0FXV53P3FoiLT8AvazYjJjYWTlUdsWLBbA4jfiB7VvwBhaEBRviNhJGJEcLPX8cPXjOQ+cbaO1a21jB5Y56OY50qmLltjurxwGlDAQDHdwRi6beLUca6LBq0bQgAWBDws9r5pveajGtnNd++TgXTvlEdxCWmYNmuY4hJSEK1yuWxbMIglP13GDEyJh7yNyrwwzxbQSaTYemOo4iOS4S5iRFa1HXCqB5t1Y579todPHsRD88W9T/o9XzM2rlWQ1xSGpbvD0ZMUiqqVSiHZSO7oqyJEQDgWVyS2mjKsPYNIQOwdN8ZRCckw9zYEJ/WdsCoTq8Xnd5x6goAYKj/DrVzzezfFl0a15T+okqCIjavaunSpZg3bx4iIyPh7OyMJUuWwM1N800RAODv74/ly5fj4cOHsLCwQPfu3eHn5wcDA2nuSJUJgvB2lTzfXr58iRs3buDixYtQKBQFqmplxhR8XgwVHX1cxxV2CKQlm3d6F3YIpEVCguY7Mqn4KeX+ZaGdO+3wL5Iev1S7Ufnuu23bNnh5eWHFihVo2LAh/P39sWPHDty8eROWlpa5+m/ZsgWDBw/GunXr0KRJE9y6dQsDBw5E7969JSsYFaheamBggLp166Ju3braioeIiIiKOonnVWlaIkqhUGic371w4UIMGzYMgwYNAgCsWLECBw4cwLp16zBp0qRc/f/++280bdoUffv2BQDY2dmhT58+CAkJydVXW/hF1ERERFSkaFoiys/PL1e/jIwMXLhwAe7u7qo2uVwOd3d3BAcHazx2kyZNcOHCBYSGhgIA7t69i4MHD6JDB+mW/+BMQCIiIhJH4sqWpiWiNFW1YmJikJ2dDSsrK7V2KysrtfVA39S3b1/ExMSgWbNmEAQBWVlZ+PLLLzF58mTtXcBbWNkiIiIicSRe1FTKJaJOnDiBOXPmYNmyZbh48SL++OMPHDhwALNnz9bK8TVhZYuIiIiKJQsLC+jo6CAqSv1LxKOiomBtba1xn6lTp2LAgAEYOvTV3eO1a9dGSkoKhg8fju+//15tEWNtYWWLiIiIxCkii5rq6+vD1dUVgYGBb4SmRGBgIBo3bqxxn9TU1FwJlc6/6+YVYIGGd2Jli4iIiIotHx8feHt7o379+nBzc4O/vz9SUlJUdyd6eXmhQoUKqgn2nTp1wsKFC1G3bl00bNgQERERmDp1Kjp16qRKurSNyRYRERGJU4QWNe3VqxeeP3+OadOmITIyEi4uLggICFBNmn/48KFaJWvKlCmQyWSYMmUKnjx5gnLlyqFTp0748ccfJYuxQIuaahMXNS1ZuKhpycFFTUsWLmpachTqoqZ/zpX0+KW6TJD0+B8aK1tEREQkTgn8smgpcYI8ERERkYRY2SIiIiJxitCcreKAlS0iIiIiCbGyRUREROJwzpYoTLaIiIhIHCZbonAYkYiIiEhCrGwRERGROEVjic5ig5UtIiIiIgmxskVERETicM6WKKxsEREREUmIlS0iIiISh5UtUVjZIiIiIpIQK1tEREQkDr+uRxQmW0RERCQOhxFF4TAiERERkYRY2SIiIiJxuKipKKxsEREREUmIlS0iIiISh3O2RGFli4iIiEhCrGwRERGROKxsicLKFhEREZGEWNkiIiIicbioqShMtoiIiEgUQcmlH8TgMCIRERGRhFjZIiIiInE4QV4UVraIiIiIJMTKFhEREYnDCfKisLJFREREJCFWtoiIiEgc3o0oCitbRERERBJiZYuIiIjE4d2IojDZIiIiInGYbInCYUQiIiIiCbGyRUREROIInCAvBitbRERERBJiZYuIiIjE4ZwtUVjZIiIiIpIQK1tEREQkDhc1FYWVLSIiIiIJsbJFRERE4vCLqEVhskVERETicBhRFA4jEhEREUmoyFS2+riOK+wQSIt+v+Bf2CGQlpSyaV7YIZAWmSgMCzsE0pLYpC8L7dwCl34QhZUtIiIiIgkVmcoWERERFROcsyUKK1tEREREEmJli4iIiMTh0g+isLJFREREJCFWtoiIiEgcztkShckWERERicOlH0ThMCIRERGRhFjZIiIiInE4jCgKK1tERERUrC1duhR2dnYwMDBAw4YNERoa+s7+8fHxGDlyJMqXLw+FQoFPPvkEBw8elCw+VraIiIhInCK09MO2bdvg4+ODFStWoGHDhvD390e7du1w8+ZNWFpa5uqfkZGBNm3awNLSEjt37kSFChXw4MEDmJmZSRYjky0iIiIqthYuXIhhw4Zh0KBBAIAVK1bgwIEDWLduHSZNmpSr/7p16xAbG4u///4benp6AAA7OztJY+QwIhEREYmjFCTd0tPTkZiYqLalp6fnCiMjIwMXLlyAu7u7qk0ul8Pd3R3BwcEaQ9+7dy8aN26MkSNHwsrKCrVq1cKcOXOQnZ0t2cvFZIuIiIiKFD8/P5iamqptfn5+ufrFxMQgOzsbVlZWau1WVlaIjIzUeOy7d+9i586dyM7OxsGDBzF16lQsWLAAP/zwgyTXAnAYkYiIiEQSJF5ny9fXFz4+PmptCoVCK8dWKpWwtLTEqlWroKOjA1dXVzx58gTz5s3D9OnTtXKOtzHZIiIiInEkXvpBoVDkK7mysLCAjo4OoqKi1NqjoqJgbW2tcZ/y5ctDT08POjo6qrbq1asjMjISGRkZ0NfXL1jwGnAYkYiIiIolfX19uLq6IjAwUNWmVCoRGBiIxo0ba9ynadOmiIiIgPKN6tytW7dQvnx5SRItgMkWERERiSXxBHkxfHx8sHr1amzcuBE3btzAV199hZSUFNXdiV5eXvD19VX1/+qrrxAbG4uxY8fi1q1bOHDgAObMmYORI0dq9SV6E4cRiYiIqNjq1asXnj9/jmnTpiEyMhIuLi4ICAhQTZp/+PAh5PLXtaVKlSrh8OHD+Oabb1CnTh1UqFABY8eOxcSJEyWLUSYIQpFYc7975c6FHQJp0e8X/As7BNKSUjbNCzsE0iIThWFhh0BaEpt0u9DOnfxtF0mPbzz/T0mP/6FxGJGIiIhIQhxGJCIiInH4RdSisLJFREREJCFWtoiIiEgUgZUtUZhsERERkThMtkThMCIRERGRhFjZIiIiInEk/m7EkoaVLSIiIiIJsbJFRERE4nDOliisbBERERFJiJUtIiIiEoeVLVFY2SIiIiKSECtbREREJIogsLIlBitbRERERBJiZYuIiIjE4ZwtUZhsERERkThMtkThMCIRERGRhFjZIiIiIlEEVrZEYWWLiIiISEKsbBEREZE4rGyJwsoWERERkYRY2SIiIiJxlIUdQPHCyhYRERGRhFjZIiIiIlF4N6I4TLaIiIhIHCZbonAYkYiIiEhCrGwRERGROJwgLworW0REREQSYmWLiIiIROEEeXFY2SIiIiKSECtbREREJA7nbInCyhYRERGRhN472Tp58iQOHz6MrKwsbcZTLPXy6YvV5zbgt5s7MO23WbC2K//O/tXdamLS2ilYFboeOx/sRYO2DdWe19HVQf9J3lhw+GdsvrEdq0LXY/TCcTC3LCPlZXzUzof9g5ETpqNV536o1fRzBJ78+z/3Cb14BT0GjULdlp3wec/B2HPgaK4+v+/ah7bdvFGvVWf0GTYO/1y/KUX4lIcZ07/FowcXkZQQgcOHtqJKFft87zvhu5HIyniCBfNnqrUvW/oTbt44g6SECDx7cgV/7FqHatUctR06aeD7/Vhcv30GT6L/wR97N8DBsfI7+w8a0hengvfhwZNLePDkEg4Hbod7m09Vz1eyrYDYpNsaty6e7aW+nGJNUAqSbiWN6GQrJiYG3t7eaNmyJSZMmIDHjx9LEVex4fnlF+gwsCNWTV6OyV2+Q3pqOqZumgk9hV6e+xgYKnD/xj2smbpS4/OKUgrY13LEzp+3YYLHN5g34n+wcaiASWu/l+oyPnppaS9RrYoDvh//db76P34aiZHfTYNbPWfs3LAUA3p6YvpP/jgTckHV59CxvzB3ySp8NbgfdqxbgmpV7DHCZwpexMVLdBX0pu++/RqjRg7G16MmoUmzTkhJTcXB/b9BoVD85771XZ0xbGh/XL5yPddzFy9ewdBhPqhVpyU6ePSFTCbDoQO/Qy7nQIGUxnwzHMO/9ML4cdPQplV3pKamYefu9VAo9PPc5+nTSMycPh+tPvXEZy264uRfwdi8dTmcnKoAAJ48fgYnx8Zqm98Pi5GUlIxjR09+qEsrnpQSbyWMqJ8OWVlZ2LFjB6KiorB161ZERERg69atyMjIkCq+Is9jSGfs+mU7zh0NwYPw+1jiswjmlmXg1rZRnvtcOnERW+f/htDDZzU+n5qUitn9pyH4wBk8vfsEty/dxJppK+FYpyosbCykupSPWvPGDTBmuDfcWzTNV//tew6gQnlrfDd6GBztbNG3e2e0adkMv27brerz67bd6N7pc3T1aAtH+8qY9t1oGCgU2L3/iFSXQW8YM3oo5vgtxr59R/DPPzcwcNBY2NhYoUuXdu/cz8jIEL/++gu+/GoC4jUkxmvW/oZTp0Pw4MFjXAq7imnT58LWtgLs7CpJdCUEAF9+7Y0F85bh0IFAXL92E18N/w7W5S3h0bFNnvscPhSEY0f+wt07D3An4j5+nLUIKcmpqO/mAgBQKpWIjo5R2zw6tcGfuw8hJSX1A10ZfQxEJVu6urqoV68eRo4ciZ49e2LixIlYuHAhrl/P/dffx8CykhXMLcvgyunLqrbUpFTcDruFT+pV0+q5DEsbQalUIiUxRavHpfdz+Wo4GtV3UWtr2tAVl6/eAABkZmbi+s3baNTgdR+5XI5G9V1UfUg69va2KF/eCoFBp1VtiYlJCA29hEYNXd+575Kf5+DQwUAEBp36z/MYGpbCQK9euHv3AR49elrguEmzynaVYG1tiRPHXw/vJyUm48L5y2jgVjdfx5DL5fiimwcMjQxxLiRMYx9nl5qo41wDm3/doY2wSzRBKe1W0oiue7u5uaFTp04AgGnTpkFPTw/Lly9HUlJSvo+Rnp6OxMREtS1byBYbSqEztzQHAMTHxKu1J8TEw6ycudbOo6fQQ39fb5zZexJpyWlaOy69v5jYOJQto/4elzU3Q3JKKl6mpyMuPhHZ2crcfcqYIyY27kOG+lGytrIEAERFPVdrj4qOgbW1ZZ779ezZGXXr1sLkKX7vPP6XI7wRH3sLifERaNe+Fdp36IPMzMyCB04aWVm9qug/j45Ra38eHQNLq3dX+6vX+AQPn4Uh8sU1LPCfhQF9v8bNmxEa+/b36oGb4REIDbmkncCJ/iU62ZLJZACgGjpcvHgx1q1bh7NnNQ+JaeLn5wdTU1O17WaC5g9/UdLcswU2Xd+m2nR0dSQ/p46uDnyWToBMJsOq75dLfj6i4qhPn66Ij72l2vT0xK9qU7GiDRYtmAUv79FIT09/Z98tv/+B+m7t0OqzL3D79l38vmVFvuaCUf5079kZD5+FqTZd3bznwP6XiNv30KJpZ7Rp1R3r1m7BspVzUa1alVz9DAwU6N6jE6ta+cU5W6K89zpb+vqvJiV2794dCxcuxNy5c+Hs7AxLS0tERkbC2to6z319fX3h4+Oj1uZdq8/7hvLBnDsaituXbqke6+q/evnMLMwQH/26WmFqYYb71+8W+Hw5iVa5CpaY0WcKq1pFiEUZc7x4q0L1Ii4exkaGMFAooGMmh46OPHef2DhYlNFe1ZNe2bfvCEJDX1cjciZNW1mVQ2RktKrdytICYZevaTxGvXq1YWVVDudCAlRturq6aN68EUZ+PRCGxvZQKl/9FkhMTEJiYhIiIu7hbMhFxERfh6dne2zb9qcUl/fRCTgYiAvnw1SPFf/+vilnaaFWrSxnaYGrV949LJ+ZmYl7dx8CAC6HXUPderUx4mtv+Iydqtavs2d7lDI0wNbf92jnIojeUKBFTbOysqCrq4vVq1fD2dkZW7duxZ07dxAcHIyVK1eibl3NY+kKhSLXX4E6MumrRAX1MiUNkSnqCU9cdCxqN3XG/ev3AACljEuhqssnOLL5UIHOlZNolbe3wYze3yM5Pv/DtCQ951pOOBV8Xq0t+NwlONeqDgDQ09NDjWpVEXI+DK0/bQLg1WTckAth6NOt8wePt6RLTk5BcrL6fMZnz6LwWatmuPxvclW6tDHc3OpixapfNR4jKOg0nOt+pta2ZvVC3Lx5B/PmL1UlWm+TyWSQyWRQ6LOypS2a3s/IyGi0aNkYV/95lVyVLm0M1/rOWL9mi6hjy+Vy6Gu4g7G/Vw8EHAzCi5jY9w/8I1IS51VJqUDJlq7uq91r1qyJevXqYdy4cbC1tX1nolXSHFi7F91G98Sze08R/SgKvcf3Q1x0LEKPvB5Wnb5lNkIOn0XAxgMAAANDA7W1uKwqWcGuhj2S45MQ8zQGOro6+Hb5JNjXcoDf4NmQ68hhVs4MAJAcn4ysTK5tpm2pqWl4+Pj1BOcnT6MQfusOTE1Ko7y1JRYtX4/omBfwm/otAKCnpwd+37UPC5auRdeObRF64TIOB53EsnmzVMfw6tUV3/+4ADWdqqJWjWrYvH0P0l6mw9Mj77unSHt+XrIGk33H4HbEXdy//wgzZ3yHp0+j8Oefh1V9jgRsw54/D2HZ8g1ITk7BtWvq66ClpqTixYs4Vbu9vS169uiMo0f/wvOYF6hYwQYTJoxEWtpLHAoI/KDX97FZsWwjxn/3Ne7cuY8H9x9j8tRxiHwWjQP7X69vt3vfRhzYdxRrVm0GAEydMR7Hjp7E40dPYWxshO49O6FZ84bo7jlY7dj2DrZo0rQBenUb+kGviT4eBf66njt37sDT0xN3797F6tWrMWTIEG3EVWzsWfEHFIYGGOE3EkYmRgg/fx0/eM1AZvrrybJWttYwMTdRPXasUwUzt81RPR447dU/8OM7ArH028UoY11WtdDpgoCf1c43vddkXDt7VcpL+ihdDb+NwaMnqh7PXbIKANDlc3f8OGU8Yl7E4lnU6+GoijbWWDpvFub+vBKbd+yBVTkLzJw4Dk3fuNPtc/cWiItPwC9rNiMmNhZOVR2xYsFsDiN+IPPmL4ORkSFWLJsLMzMTnDlzDh6d+qvNx3JwqAwLi/wvFvzyZTqaNXXDmNFDYW5uiqioGJw6fRbNW3TB8+cvpLgM+tfPi1bByLAUFv38A0xNTXA2+Dx6fDEY6emvlx6yt7dF2bKv/32VK1cWy1fOhZW1JRITk3Dtaji6ew7GieNn1I7db0B3PH0SiaDA06B8YmVLFJkgCAVaqvX+/fvYsGEDJk6ciFKlSr33cbpX5tBKSfL7Bf/CDoG0pJRN88IOgbTIRGFY2CGQlsQm3S60cz9v00LS45c7+pekx//QClzZsrOzw4wZM7QQChEREVHJU+Bki4iIiD4unCAvDr/Mi4iIiEhCrGwRERGRKKxsicPKFhEREZGEWNkiIiIicQRZYUdQrLCyRURERCQhVraIiIhIFM7ZEofJFhEREYkiKDmMKAaHEYmIiIgkxMoWERERicJhRHFY2SIiIqJibenSpbCzs4OBgQEaNmyI0NDQfO23detWyGQyeHp6Shofky0iIiISRRBkkm5ibNu2DT4+Ppg+fTouXrwIZ2dntGvXDtHR0e/c7/79+/j222/RvHnzgrwU+cJki4iIiIqthQsXYtiwYRg0aBBq1KiBFStWwNDQEOvWrctzn+zsbPTr1w8zZ86Eg4OD5DEy2SIiIiJRBKW0W3p6OhITE9W29PT0XHFkZGTgwoULcHd3V7XJ5XK4u7sjODg4z/hnzZoFS0tLDBkyRJLX521MtoiIiKhI8fPzg6mpqdrm5+eXq19MTAyys7NhZWWl1m5lZYXIyEiNxz59+jTWrl2L1atXSxK7JrwbkYiIiESRep0tX19f+Pj4qLUpFIoCHzcpKQkDBgzA6tWrYWFhUeDj5ReTLSIiIhJFEKQ9vkKhyFdyZWFhAR0dHURFRam1R0VFwdraOlf/O3fu4P79++jUqZOqTal8tY6Frq4ubt68CUdHxwJGnxuHEYmIiKhY0tfXh6urKwIDA1VtSqUSgYGBaNy4ca7+Tk5O+OeffxAWFqbaOnfujFatWiEsLAyVKlWSJE5WtoiIiEiUovR1PT4+PvD29kb9+vXh5uYGf39/pKSkYNCgQQAALy8vVKhQAX5+fjAwMECtWrXU9jczMwOAXO3axGSLiIiIiq1evXrh+fPnmDZtGiIjI+Hi4oKAgADVpPmHDx9CLi/cgTyZIEg98po/3St3LuwQSIt+v+Bf2CGQlpSykX7BP/pwTBSGhR0CaUls0u1CO/d9lzaSHt8u7Kikx//QOGeLiIiISEIcRiQiIiJRisaYWPHByhYRERGRhFjZIiIiIlGK0t2IxQGTLSIiIhJFEJhsicFhRCIiIiIJsbJFREREogjKwo6geGFli4iIiEhCrGwRERGRKErO2RKFlS0iIiIiCbGyRURERKLwbkRxWNkiIiIikhArW0RERCQKFzUVh8kWERERicLvRhSHw4hEREREEmJli4iIiEThMKI4rGwRERERSYiVLSIiIhKFi5qKw8oWERERkYRY2SIiIiJRuKipOKxsEREREUmIlS0iIiIShetsicNki4iIiEThBHlxOIxIREREJCFWtoiIiEgUTpAXh5UtIiIiIgmxskVERESicIK8OKxsEREREUmIlS0iIiIShXcjisPKFhEREZGEikxla/NO78IOgbSolE3zwg6BtCTt6anCDoG0SEhLKuwQqATg3YjisLJFREREJKEiU9kiIiKi4oFztsRhskVERESicOUHcTiMSERERCQhVraIiIhIFA4jisPKFhEREZGEWNkiIiIiUbj0gzisbBERERFJiJUtIiIiEkVZ2AEUM6xsEREREUmIlS0iIiISRQDnbInBZIuIiIhEUXJVU1E4jEhEREQkIVa2iIiISBQlhxFFYWWLiIiISEKsbBEREZEonCAvDitbRERERBJiZYuIiIhE4aKm4rCyRURERCQhVraIiIhIFM7ZEofJFhEREYnCYURxOIxIREREJCFWtoiIiEgUVrbEYWWLiIiIirWlS5fCzs4OBgYGaNiwIUJDQ/Psu3r1ajRv3hzm5uYwNzeHu7v7O/trA5MtIiIiEkWATNJNjG3btsHHxwfTp0/HxYsX4ezsjHbt2iE6Olpj/xMnTqBPnz44fvw4goODUalSJbRt2xZPnjzRxkujkUwQhCLx3d0vz+0q7BBIi4ybjinsEEhL0p6eKuwQSIuEtKTCDoG0RL+Sc6Gd+4BVH0mP7/5wA9LT09XaFAoFFApFrr4NGzZEgwYN8MsvvwAAlEolKlWqhNGjR2PSpEn/ea7s7GyYm5vjl19+gZeXl3Yu4C2sbBEREZEoSpm0m5+fH0xNTdU2Pz+/XHFkZGTgwoULcHd3V7XJ5XK4u7sjODg4X9eSmpqKzMxMlClTRmuvz9s4QZ6IiIiKFF9fX/j4+Ki1aapqxcTEIDs7G1ZWVmrtVlZWCA8Pz9e5Jk6cCBsbG7WETduYbBEREZEoSokXNc1ryFDb/ve//2Hr1q04ceIEDAwMJDsPky0iIiISpUhM9gZgYWEBHR0dREVFqbVHRUXB2tr6nfvOnz8f//vf/3Ds2DHUqVNHyjA5Z4uIiIiKJ319fbi6uiIwMFDVplQqERgYiMaNG+e539y5czF79mwEBASgfv36ksfJyhYRERGJUpQWNfXx8YG3tzfq168PNzc3+Pv7IyUlBYMGDQIAeHl5oUKFCqoJ9j/99BOmTZuGLVu2wM7ODpGRkQAAY2NjGBsbSxIjky0iIiIqtnr16oXnz59j2rRpiIyMhIuLCwICAlST5h8+fAi5/PVA3vLly5GRkYHu3burHWf69OmYMWOGJDFynS2SBNfZKjm4zlbJwnW2So7CXGdrZ/l+kh6/+7PfJD3+h8Y5W0REREQS4jAiERERiVIkhsSKEVa2iIiIiCTEyhYRERGJUpTuRiwOmGwRERGRKEppF5AvcTiMSERERCQhVraIiIhIFKm/G7GkYWWLiIiISEKsbBEREZEoXPpBHFa2iIiIiCTEyhYRERGJwrsRxWFli4iIiEhCrGwRERGRKFzUVBwmW0RERCQKJ8iLw2FEIiIiIgmxskVERESicIK8OKxsEREREUmIla0C2no0GBsPnEJMQjI+sbXGJK9OqO1YKc/+mwPOYPuxEES+iIdZaSO0cauFMT3bQqGvBwD4fNxcPI2Jz7VfL/eGmDywi1SXQW+YMf1bDBncF2ZmJvj77/MYOdoXERH38rXvhO9GYs6Pk7H45zUY/+10VfuypT+h9WfNYGNjheTkVASfPQ/fyT/i5s07Ul3GR+t82D9Yv2UnrodH4PmLWCz2m4rWnzZ55z6hF69g3pJViLj3ANaW5TDCuw88Pdqo9fl91z6s37ITMbFxqFbFAZO/+Qq1a1ST8lLoX7//GYAN2/chJjYe1Rwrw3fUYNR2qqKxb2ZWFtb8vgd7j/yF6JhY2FWywTdD+6GZm4tav6iYWCxavRmnQ8PwMj0dlWys8cN3X6NmNccPcEXFHyfIi/Pela2jR49izJgx8Pf3R2hoqDZjKjYCzl7B/N8OYkTX1tj6w0hUsy2Pr35ajxcJyRr7H/w7DIu3HcaXX3yG3XO/wYxhX+Dw2Sv4efsRVZ/fZn2NwF98VdvKSYMBAG3can+Qa/rYffft1xg1cjC+HjUJTZp1QkpqKg7u/w0KheI/963v6oxhQ/vj8pXruZ67ePEKhg7zQa06LdHBoy9kMhkOHfgdcjmLy9qWlvYS1ao44PvxX+er/+OnkRj53TS41XPGzg1LMaCnJ6b/5I8zIRdUfQ4d+wtzl6zCV4P7Yce6JahWxR4jfKbgRVy8RFdBOQKO/415K37FlwO6Y/uKn/CJQ2WMmPQjXsQlaOy/ZP1W7Nx/FL6jBmHP2oXo2bENxs2Yhxu3X//BlJCUDK+xU6Grq4vlfpOxZ+0ifPelF0xKG32oy6KPjOif9M+ePUOnTp3Qv39/xMbGYt26dWjbtu1HmXBtOnQaX7RqAM8WrnCsYIUpg7rAQKGPPX9d0Ng/7PZDuFS1RYcmLqhQzhxNaldF+8bOuHr3sapPGRNjWJiVVm0nL4WjkmUZ1K9u/6Eu66M2ZvRQzPFbjH37juCff25g4KCxsLGxQpcu7d65n5GRIX799Rd8+dUExGv4Bbxm7W84dToEDx48xqWwq5g2fS5sbSvAzi7vKii9n+aNG2DMcG+4t2iar/7b9xxAhfLW+G70MDja2aJv985o07IZft22W9Xn12270b3T5+jq0RaO9pUx7bvRMFAosHv/kXccmbTh11370a1Da3Rt3wqOlSti2rhhKKXQx+6A4xr77z92CkP7dsWnDeuhko0VenVui+ZudbFx5z5Vn3Vb/4R1ubL44buvUdupCiqWt0ST+s6oZGP9oS6r2FNKvJU0opKt1NRU+Pr6wsjICGfPnsXmzZtx5coVVKtWDStXrgQAKJUl8WXKLTMrCzfuPUWjmq9L2XK5HI1qOuJKxEON+7hUtcWN+0/xz51HAIDH0bE4ffkmmjtrHorIzMrCgTNh8GxRHzIZZyNKzd7eFuXLWyEw6LSqLTExCaGhl9Cooes7913y8xwcOhiIwKBT/3keQ8NSGOjVC3fvPsCjR08LHDcVzOWr4WhU30WtrWlDV1y+egMAkJmZies3b6NRg9d95HI5GtV3UfUhaWRmZuH6rbtoVO91ZV8ul6NRvdq4fP2Wxn0yMjKh0NdXa1Mo9HHp6k3V4xPB51HjEwf4zFqIFt2HoseICdh54Jg0F0EEkXO2DA0NoVAo0Lt3b9jb2yMrKwu6urro0KEDDh06BAD5GhZJT09Henq6WpuQkamat1QcxCWlIlupRFlTY7X2sqbGuPfsucZ9OjRxQVxSKgbOWgVAQFa2Ej1au2Fol5Ya+wedv46k1Jfo/Gk9LUdPmlhbWQIAoqLU37+o6BhYW1vmuV/Pnp1Rt24tNGrs8c7jfznCG//z+x7GxkYIvxmB9h36IDMzs+CBU4HExMahbBlztbay5mZITknFy/R0JCYmIztbmbtPGXPce/gYJJ24hMRXP2fNzdTay5qb4V4ef6g0qe+MX3fuh2vt6qhkY4Wzl64i8HQost8oBDx+Fo3t+47Cq7sHhvXpiqs37+B/S9dDT08XXdq2lPCKSg6Bf/+LInoY8ZdffkH79u1f7fxvYnXr1i3UqVMHACAI/73UmZ+fH0xNTdW2eRv+EBtKsXPu+l2s3XsC3w/sjK0/jMLCsf1wKuwmVu4O0th/918X0NT5E1iam3zgSD8Offp0RXzsLdWmpyf+fpGKFW2waMEseHmPzvUHxNu2/P4H6ru1Q6vPvsDt23fx+5YV+ZoLRkT5N2nkINhWsEbnweNQr31f+C1Ziy7tWkL+xuiAUlCielV7jB3SF9Wr2qNHR3d069Aa2/cdLcTIixcOI4oj+reLnt7r6lNOsvXgwQMMGzYs38fw9fWFj4+PWpvwz0GxoRQq89KG0JHLc02Gf5GQDAvT0hr3WbrzKDo2rYsvWjUAAFStZI209AzMXrcHw7q0VKsKPo2JQ8jVCCwc10+6i/jI7dt3BKGhl1SPFYpXQw9WVuUQGRmtareytEDY5Wsaj1GvXm1YWZXDuZAAVZuuri6aN2+EkV8PhKGxvWpoPTExCYmJSYiIuIezIRcRE30dnp7tsW3bn1JcHuWTRRlzvIiNU2t7ERcPYyNDGCgU0DGTQ0dHnrtPbBws3qp2kXaZm5q8+jn71jzIF3HxuapdOcqYmeDnWROQnpGB+MRkWJY1x6I1v6FieStVn3JlzOFYuaLafg62FXHsVIi2L4EIgBbW2bp79y4iIiJQq1YtAIBMJvvPoRGFQgETExO1rTgNIQKAnq4uqtvbIORahKpNqVQi5Nod1Kliq3GflxmZkMnVa686/yZYb9cD//zrAsqYGKO5C28tl0pycgru3Lmv2q5fv4Vnz6LwWatmqj6lSxvDza0uzoZovukhKOg0nOt+BtcGbVXbufNh2PL7brg2aJvnHEaZTAaZTAaFPitbhc25lhNCLlxWaws+dwnOtaoDePUHZo1qVRFyPkz1vFKpRMiFMFUfkoaeni5qfOKAkItXVW1KpRJnL12Fc41P3rmvQl8fVhZlkJWdjWOnQtCqSX3Vcy41q+H+W8OQ9x8/RXmrctq9gBKMlS1x3jvZyhkuPH36NIyNjeHq+moC8cyZMzFmzBhER0e/a/cSYcDnzfDHifPYe/Ii7j6Jxg/r/0RaegY8W7yaY/X9ih1YvO2wqn+Luk7YcSwEh4Iv43F0LIL/uY2lO4/i07pOqqQLePXD5M+TF9GpeV3o6uh88Ov6mP28ZA0m+45Bx45tUKuWEzasX4ynT6Pw55+v38cjAdvw9VcDAbxK2K5du6m2paak4sWLOFy79mpCrr29LSZOGIV6dWujUiUbNG5UH9u2rkRa2kscCggsjMss0VJT0xB+6w7Cb71aw+zJ0yiE37qDZ/9WKxctXw/f2fNV/Xt6euDx02dYsHQt7j54hK1/7MfhoJPw6tVV1cerV1fs3BeAPw8exZ37DzF7/i9Ie5meay0u0j6vbh2x62Ag/jxyAncfPMbsxWtevfbtWwIAJv/vF/iv2aLqf+XGbRw7FYJHT6Nw4Z8b+Mp3DpRKAYN6dXnjmB64cuM2Vm/5Aw+fROJA4GnsOhiI3v9x1zHR+3rvRU1z7o4LDQ1Ft27dcPToUQwfPhypqanYtGkTLC3znlBcUrRvVAdxiSlYtusYYhKSUK1yeSybMAhl/x1GjIyJV5snMMyzFWQyGZbuOIrouESYmxihRV0njOrRVu24Z6/dwbMX8fBsUR/0Yc2bvwxGRoZYsWwuzMxMcObMOXh06q82H8vBoTIsLMrk+5gvX6ajWVM3jBk9FObmpoiKisGp02fRvEUXPH/+QorL+KhdDb+NwaMnqh7PXbIKANDlc3f8OGU8Yl7E4lnU6z8GK9pYY+m8WZj780ps3rEHVuUsMHPiODR94w7Uz91bIC4+Ab+s2YyY2Fg4VXXEigWzOYz4AbRv1QSxCYlYumE7YuLi4eRohxV+k2Hx7zDis+gYtRGD9IxMLFm/FY+fRcOwlAGau9XFnImjYGL8eg2tWk5V4D/zW/iv2YIVm3ahQnlLTPjKGx1bN//Ql1ds8YuoxZEJ+ZnRnoeXL1+idu3auHPnDvT19TFz5kxMnDjxv3fUdKxzu943DCqCjJuOKewQSEvSnv73chZUfAhpSYUdAmmJfiXnQjv3kkr9JT3+6EebJT3+h1agr+sxMDCAnZ0d2rRpg4ULF8LAwEBbcREREVERxS+iFqfA340YEBAAHc4rIiIiItKowMkWEy0iIqKPS0m8Y1BKBU62iIiI6OPCZEucAq+zRURERER5Y2WLiIiIROHSD+KwskVEREQkIVa2iIiISBQu/SAOK1tEREREEmJli4iIiETh3YjisLJFREREJCFWtoiIiEgU3o0oDitbRERERBJiZYuIiIhEUbK2JQqTLSIiIhKFE+TF4TAiERERkYRY2SIiIiJROIgoDitbRERERBJiZYuIiIhE4ZwtcVjZIiIiIpIQK1tEREQkCr+IWhxWtoiIiIgkxMoWERERicJFTcVhskVERESiMNUSh8OIRERERBJiskVERESiKCXexFq6dCns7OxgYGCAhg0bIjQ09J39d+zYAScnJxgYGKB27do4ePDge5w1/5hsERERUbG1bds2+Pj4YPr06bh48SKcnZ3Rrl07REdHa+z/999/o0+fPhgyZAguXboET09PeHp64urVq5LFKBMEoUgMvb48t6uwQyAtMm46prBDIC1Je3qqsEMgLRLSkgo7BNIS/UrOhXbuiXZ9JD3+T/d/z3ffhg0bokGDBvjll18AAEqlEpUqVcLo0aMxadKkXP179eqFlJQU7N+/X9XWqFEjuLi4YMWKFQUPXgNWtoiIiKhISU9PR2JiotqWnp6eq19GRgYuXLgAd3d3VZtcLoe7uzuCg4M1Hjs4OFitPwC0a9cuz/7awGSLiIiIRBEk3vz8/GBqaqq2+fn55YojJiYG2dnZsLKyUmu3srJCZGSkxtgjIyNF9dcGLv1ARERERYqvry98fHzU2hQKRSFFU3BMtoiIiEgUqb+IWqFQ5Cu5srCwgI6ODqKiotTao6KiYG1trXEfa2trUf21gcOIREREJIoSgqRbfunr68PV1RWBgYGvY1MqERgYiMaNG2vcp3Hjxmr9AeDo0aN59tcGVraIiIio2PLx8YG3tzfq168PNzc3+Pv7IyUlBYMGDQIAeHl5oUKFCqo5X2PHjkWLFi2wYMECeHh4YOvWrTh//jxWrVolWYxMtoiIiEiUIrFm1L969eqF58+fY9q0aYiMjISLiwsCAgJUk+AfPnwIufz1QF6TJk2wZcsWTJkyBZMnT0bVqlWxZ88e1KpVS7IYuc4WSYLrbJUcXGerZOE6WyVHYa6z9Y1db0mPv+j+VkmP/6GxskVERESiSD1BvqThBHkiIiIiCbGyRURERKIIRWrWVtHHyhYRERGRhFjZIiIiIlE4Z0scJltEREQkipiFR4nDiERERESSYmWLiIiIRGFdSxxWtoiIiIgkxMoWERERicI5W+KwskVEREQkIVa2iIiISBQu/SAOK1tEREREEmJli4iIiETh1/WIw2SLiIiIROEwojgcRiQiIiKSUJGpbAkJzws7BNIiE4VhYYdAWiKkJRV2CKRFslKlCzsEKgE4jCgOK1tEREREEioylS0iIiIqHjhnSxxWtoiIiIgkxMoWERERiaIUOGdLDFa2iIiIiCTEyhYRERGJwrqWOEy2iIiISBQl0y1ROIxIREREJCFWtoiIiEgULmoqDitbRERERBJiZYuIiIhE4aKm4rCyRURERCQhVraIiIhIFN6NKA4rW0REREQSYmWLiIiIROHdiOIw2SIiIiJROEFeHA4jEhEREUmIlS0iIiISRRA4jCgGK1tEREREEmJli4iIiETh0g/isLJFREREJCFWtoiIiEgU3o0oDitbRERERBJiZYuIiIhE4aKm4jDZIiIiIlE4QV4cDiMSERERSYiVLSIiIhKFi5qKw8oWERERkYRY2SIiIiJRuPSDOKxsEREREUmIlS0iIiIShUs/iMPKFhEREZGEWNkiIiIiUbjOljisbBERERFJiJUtIiIiEoXrbInDZIuIiIhE4TCiOBxGJCIiIpIQky0iIiISRZD4P6nExsaiX79+MDExgZmZGYYMGYLk5OR39h89ejSqVauGUqVKwdbWFmPGjEFCQoKo8zLZIiIioo9Cv379cO3aNRw9ehT79+/HyZMnMXz48Dz7P336FE+fPsX8+fNx9epVbNiwAQEBARgyZIio88qEIjLLLe3YisIOgbSoQtcFhR0CaUnk9Z2FHQJpkaxU6cIOgbREz8Kh0M79aYXWkh7/5JNArR/zxo0bqFGjBs6dO4f69esDAAICAtChQwc8fvwYNjY2+TrOjh070L9/f6SkpEBXN39T31nZIiIioiIlPT0diYmJalt6enqBjhkcHAwzMzNVogUA7u7ukMvlCAkJyfdxEhISYGJiku9EC2CyRURERCIJEm9+fn4wNTVV2/z8/AoUc2RkJCwtLdXadHV1UaZMGURGRubrGDExMZg9e/Y7hx41YbJFRERERYqvry8SEhLUNl9fX419J02aBJlM9s4tPDy8wDElJibCw8MDNWrUwIwZM0Tty3W2iIiISBSp19lSKBRQKBT56jt+/HgMHDjwnX0cHBxgbW2N6OhotfasrCzExsbC2tr6nfsnJSWhffv2KF26NHbv3g09Pb18xZaDyRYRERGJUpQWNS1XrhzKlSv3n/0aN26M+Ph4XLhwAa6urgCAoKAgKJVKNGzYMM/9EhMT0a5dOygUCuzduxcGBgaiY+QwIhEREZV41atXR/v27TFs2DCEhobizJkzGDVqFHr37q26E/HJkydwcnJCaGgogFeJVtu2bZGSkoK1a9ciMTERkZGRiIyMRHZ2dr7PzcoWERERiVJEVo0S7bfffsOoUaPQunVryOVydOvWDT///LPq+czMTNy8eROpqakAgIsXL6ruVKxSpYrase7duwc7O7t8nZfJFhEREX0UypQpgy1btuT5vJ2dnVoi2bJlS60klky2iIiISJSiNGerOOCcLSIiIiIJsbJFREREokj5ZdElUYErW8V1khwRERHRh/Dela1Dhw5h3bp1sLKyQtOmTdGtWzfo6+trM7ZiYetfYdh47AJeJKbgkwrlMLFnK9S2y3txtM1BF7Hj1BVExiXCzKgU3OtWxZguzaDQe/VWrD0cisCwCNyPioVCTxfODjYY59kMdlZlPtQlffR8vx+LAQN7wtTUBCFnL+Dbb6bj7p0HefYfNKQvBg/tA1vbigCA8PDbmPe/X3Ds6EkAQCXbCrh87YTmfQeMxp97ArR+DQT8/mcANmzfh5jYeFRzrAzfUYNR26mKxr6ZWVlY8/se7D3yF6JjYmFXyQbfDO2HZm4uav2iYmKxaPVmnA4Nw8v0dFSyscYP332NmtUcP8AVfZzOh/2D9Vt24np4BJ6/iMViv6lo/WmTd+4TevEK5i1ZhYh7D2BtWQ4jvPvA06ONWp/fd+3D+i07ERMbh2pVHDD5m69Qu0Y1KS+lRGGhRRzRla0nT57Aw8MD3t7eqFChAiIjIzFs2DDs2bNHgvCKtsMXbmLBHycxokMj/D6pHz6paIGvf/kDsUmpGvsfPBeOn/88jREdGuGPqd6Y3r8tjly8hSV7z6j6XLj9GL0+dcav3/bGitHdkJWtxFdL/kBaeuaHuqyP2phvhmP4l14YP24a2rTqjtTUNOzcvR4KRd5/SDx9GomZ0+ej1aee+KxFV5z8Kxibty6H07+/2J88fgYnx8Zqm98Pi5GUlKxKyEi7Ao7/jXkrfsWXA7pj+4qf8IlDZYyY9CNexCVo7L9k/Vbs3H8UvqMGYc/ahejZsQ3GzZiHG7fvqfokJCXDa+xU6OrqYrnfZOxZuwjffekFk9JGH+qyPkppaS9RrYoDvh//db76P34aiZHfTYNbPWfs3LAUA3p6YvpP/jgTckHV59CxvzB3ySp8NbgfdqxbgmpV7DHCZwpexMVLdBUljxKCpFtJI6qylZqaijlz5sDU1BQXL15ExYqv/pKvU6cO/v77b/Ts2VOSIIuqTYEX8UWTWvBsXBMAMKW3O05dvYc9wVcxuK1brv6X7z6Fi4MNOjRwAgBUKGuK9q7V8M/911+AuWzUF2r7zBrQFp9NWonrD6PgWrWihFdDAPDl195YMG8ZDh0IBAB8Nfw73LxzFh4d2+CPXQc07nP4UJDa4x9nLcLgIX1R380F4eERUCqViI6OUevj0akN/tx9CCkpmhNzKphfd+1Htw6t0bV9KwDAtHHDcCrkInYHHMfQPp65+u8/dgrD+nbFpw3rAQB6dW6LsxevYOPOffif7xgAwLqtf8K6XFn88N3rX/oVy1vmOhZpV/PGDdC8cYN899++5wAqlLfGd6OHAQAc7Wxx8co1/LptN5o2fLVq+K/bdqN7p8/R1aMtAGDad6Nx8u9z2L3/CIYO+Lh+j9GHIaqyZWhoiB49emDWrFmqRAsAqlatig4dOiA9PV3rARZVmVnZuPEoCg2dbFVtcrkMDZ1sceXuM437ODvY4PqjaFVy9TgmHqev3UezmvZ5nic5LQMAYGok/usBSJzKdpVgbW2JE8f/VrUlJSbjwvnLaOBWN1/HkMvl+KKbBwyNDHEuJExjH2eXmqjjXAObf92hjbDpLZmZWbh+6y4a1autapPL5WhUrzYuX7+lcZ+MjEwo3poGoVDo49LVm6rHJ4LPo8YnDvCZtRAtug9FjxETsPPAMWkugt7b5avhaFTfRa2taUNXXL56A8CrRSuv37yNRg1e95HL5WhU30XVh/6bIAiSbiWN6DlbLVq0gEwmAwCcOHECQ4cOxbNnz3D79m2UKVMGo0aNQvfu3d95jPT09FyJmTIjEwp9cV/sWJjiktOQrRRQtrShWnvZ0oa4HxmncZ8ODZwQn5yGQQu3AQKQpVSiR7M6GNo+dxUMAJRKAfN2nYCLgw2q2Fho/RpInZXVq9f4+VtVqOfRMbC0evfrX73GJzgcuB0GBgqkJKdiQN+vcfNmhMa+/b164GZ4BEJDLmkncFITl5CIbKUSZc3N1NrLmpvh3qOnGvdpUt8Zv+7cD9fa1VHJxgpnL11F4OlQZCuVqj6Pn0Vj+76j8OrugWF9uuLqzTv439L10NPTRZe2LSW8IhIjJjYOZcuYq7WVNTdDckoqXqanIzExGdnZytx9ypjj3sPHHzJU+oiInrOVk2hlZmbiyJEj6Ny5M8LCwrBp0yaUL18e/v7+uH79+juP4efnB1NTU7Vt3tbD73cFxci5W4+w9nAoJvf6DL9P6oeFwzrh1LV7WHXorMb+ftuCEPH0BX4a3OEDR/px6N6zMx4+C1Nturrvn+xH3L6HFk07o02r7li3dguWrZyLatVyT8Y2MFCge49OrGoVMZNGDoJtBWt0HjwO9dr3hd+StejSriXk//68AwCloET1qvYYO6Qvqle1R4+O7ujWoTW27ztaiJETFQ7O2RLnve9G1NPTw6xZs6CrqwulUgm5XI4BAwZg8ODByMrKeue+vr6+8PHxUWtTnt74vqEUCnPjUtCRy/DircnwL5JSYWFiqHGfZfv/hodbdXzR9NXwRtUKFkjLyMTsLccwtF1DyOWvf7D7bQvCyat3se6bnrAyLy3dhXzEAg4G4sL5MNXjnGGkcpYWiIp6rmovZ2mBq1fePbyQmZmJe3cfAgAuh11D3Xq1MeJrb/iMnarWr7Nne5QyNMDW3/do5yIoF3NTE+jI5bkmO7+Ii89V7cpRxswEP8+agPSMDMQnJsOyrDkWrfkNFctbqfqUK2MOx8rq8yYdbCvi2KkQbV8CFYBFGXO8iFUfXXgRFw9jI0MYKBTQMZNDR0eeu09sHCzeqnYRaUuB1tnS1X2Vq+VUu54+fQpzc3NYWLx7yEWhUMDExERtK05DiACgp6uD6pWsEHrzkapNqRQQevMR6jiU17jPy4wstYQKgOpxzgJxgiDAb1sQgi5HYNXY7qhgYSrRFVBycgru3X2o2sLDIxAZGY0WLRur+pQubQzX+s44FypuyE8ul0Nfwx2M/b16IOBgEF7ExBY4ftJMT08XNT5xQMjFq6o2pVKJs5euwrnGJ+/cV6GvDyuLMsjKzsaxUyFo1aS+6jmXmtVw/61hyPuPn6K8VTntXgAViHMtJ4RcuKzWFnzuEpxrVQfwqlBQo1pVhLzxh5ZSqUTIhTBVH/pvgsT/lTQFXtQ0MzMTMpkMu3btwuLFizFgwADY2NhoI7Yib0DrevjjzD/Ye/Ya7ka+wI9bA5GWnokujf69O3FjAH7+87Sq/6e1HbDj1BUEnL+JJzEJCL7xAMv2/Y1PaztAR/7qrZizLQgHzoXDb1AHGCn0EZOQgpiEFLzMeHe1kLRjxbKNGP/d12jf4TNUr/EJlq2ai8hn0Tiw//VQ0e59GzF0eH/V46kzxqNx0waoZFsB1Wt8gqkzxqNZ84bYuW2v2rHtHWzRpGkDbNq4/YNdz8fKq1tH7DoYiD+PnMDdB48xe/EapL1Mh2f7lgCAyf/7Bf5rXn8Z7ZUbt3HsVAgePY3ChX9u4CvfOVAqBQzq1eWNY3rgyo3bWL3lDzx8EokDgaex62Agendp96Ev76OSmpqG8Ft3EH7rDgDgydMohN+6g2eR0QCARcvXw3f2fFX/np4eePz0GRYsXYu7Dx5h6x/7cTjoJLx6dVX18erVFTv3BeDPg0dx5/5DzJ7/y6vPx1trcRFpS4G+ricuLg6zZ8/G1atXERISgh9//BGjRo3SVmxFXjvXaohLSsPy/cGISUpFtQrlsGxkV5Q1ebXuzrO4JFXVDwCGtW8IGYCl+84gOiEZ5saG+LS2A0Z1er1A345TVwAAQ/3V5/TM7N8WXf5dYoKk8/OiVTAyLIVFP/8AU1MTnA0+jx5fDEZ6eoaqj729LcqWfT3cUK5cWSxfORdW1pZITEzCtavh6O45GCeOn1E7dr8B3fH0SSSCAk+DpNW+VRPEJiRi6YbtiImLh5OjHVb4TYbFv8OIz6JjIHujypyekYkl67fi8bNoGJYyQHO3upgzcRRMjF+voVXLqQr8Z34L/zVbsGLTLlQob4kJX3mjY+vmH/ryPipXw29j8OiJqsdzl6wCAHT53B0/ThmPmBexeBYVrXq+oo01ls6bhbk/r8TmHXtgVc4CMyeOUy37AACfu7dAXHwCflmzGTGxsXCq6ogVC2ZzGFEEZQm8Y1BKMqGA91j6+/sjISEBEydOhIHB+y9PkHZsRUHCoCKmQtcFhR0CaUnk9Z2FHQJpkawU54CWFHoWDoV27ppWDSU9/rWokjUXssBfRD127Fi16g0RERERvVbgZIuJFhER0ceFw4jiFHiCPBERERHlrcCVLSIiIvq4lMTlGaTEyhYRERGRhFjZIiIiIlE4Z0scVraIiIiIJMTKFhEREYnCOVviMNkiIiIiUTiMKA6HEYmIiIgkxMoWERERicJhRHFY2SIiIiKSECtbREREJIogKAs7hGKFlS0iIiIiCbGyRURERKIoOWdLFFa2iIiIiCTEyhYRERGJInCdLVGYbBEREZEoHEYUh8OIRERERBJiZYuIiIhE4TCiOKxsEREREUmIlS0iIiIShV9ELQ4rW0REREQSYmWLiIiIROEXUYvDyhYRERGRhFjZIiIiIlF4N6I4TLaIiIhIFC5qKg6HEYmIiIgkxMoWERERicJhRHFY2SIiIiKSECtbREREJAoXNRWHlS0iIiIiCbGyRURERKJwzpY4rGwRERERSYiVLSIiIhKF62yJw2SLiIiIROEwojgcRiQiIiKSECtbREREJAqXfhCHlS0iIiIiCTHZIiIiIlEEif+TSmxsLPr16wcTExOYmZlhyJAhSE5Ozt81CwI+//xzyGQy7NmzR9R5mWwRERHRR6Ffv364du0ajh49iv379+PkyZMYPnx4vvb19/eHTCZ7r/NyzhYRERGJUhznbN24cQMBAQE4d+4c6tevDwBYsmQJOnTogPnz58PGxibPfcPCwrBgwQKcP38e5cuXF31uVraIiIioSElPT0diYqLalp6eXqBjBgcHw8zMTJVoAYC7uzvkcjlCQkLy3C81NRV9+/bF0qVLYW1t/V7nZrJFREREogiCIOnm5+cHU1NTtc3Pz69AMUdGRsLS0lKtTVdXF2XKlEFkZGSe+33zzTdo0qQJunTp8t7n5jAiERERiSLlJHYA8PX1hY+Pj1qbQqHQ2HfSpEn46aef3nm8GzduvFcce/fuRVBQEC5duvRe++dgskVERERFikKhyDO5etv48eMxcODAd/ZxcHCAtbU1oqOj1dqzsrIQGxub5/BgUFAQ7ty5AzMzM7X2bt26oXnz5jhx4kS+YmSyRURERKIUpa/rKVeuHMqVK/ef/Ro3boz4+HhcuHABrq6uAF4lU0qlEg0bNtS4z6RJkzB06FC1ttq1a2PRokXo1KlTvmNkskVEREQlXvXq1dG+fXsMGzYMK1asQGZmJkaNGoXevXur7kR88uQJWrdujV9//RVubm6wtrbWWPWytbWFvb19vs/NCfJEREQkitQT5KXy22+/wcnJCa1bt0aHDh3QrFkzrFq1SvV8ZmYmbt68idTUVK2el5UtIiIi+iiUKVMGW7ZsyfN5Ozu7/0z23icZZLJFREREohSdGVvFA4cRiYiIiCQkE4rSLQUlXHp6Ovz8/ODr65vvW1qp6OL7WXLwvSxZ+H5SUcNk6wNKTEyEqakpEhISYGJiUtjhUAHx/Sw5+F6WLHw/qajhMCIRERGRhJhsEREREUmIyRYRERGRhJhsfUAKhQLTp0/nhM0Sgu9nycH3smTh+0lFDSfIExEREUmIlS0iIiIiCTHZIiIiIpIQky0iIiIiCTHZIiIiIpIQky0iIiIiCTHZ+kCCg4Px7Nmzwg6DiKhE4w32VBTpFnYAJV1gYCCGDRsGpVKJ7OxstG/fHj/88AOsrKwKOzR6DydPnkRaWhpat24NXV3+8ynOjh49in379sHBwQFNmjSBm5tbYYdEBXDo0CGsW7cOVlZWaNq0Kbp16wZ9ff3CDosIACtbknr06BGmTJmC/v37IzAwEIsWLUJQUBBGjhyJjIyMwg6PRIiJiYG3tzdatmyJCRMm4PHjx4UdEr2nZ8+eoVOnTujfvz9iY2Oxbt06tG3bFqGhoYUdGr2HJ0+ewMPDA97e3qhQoQIiIyMxbNgw7Nmzp7BDI1JhsiWh8PBwXL58Gd7e3nB0dET37t0xd+5cPH/+HEuWLCns8CifsrKysGPHDkRFRWHr1q2IiIjA1q1bmTAXQ6mpqfD19YWRkRHOnj2LzZs348qVK6hWrRpWrlwJAFAqlYUcJeVXamoq5syZA1NTU1y8eBH+/v7YuXMnHBwc8Pfffxd2eEQqHAeRUGxsLKpXr47s7GxVm6enJ8LDw7Fu3Tp4eXmhXLlyhRgh5Yeuri7q1auHihUrolOnTggPD8fChQvRvn17uLi4FHZ4JIKhoSEUCgV69+4Ne3t7ZGVlQVdXFx06dMChQ4cAAHI5/wYtLgwNDdGjRw9UrFgRFStWVLVXrVoVHTp0QHp6Or+yh4oEfl2PhK5evYoGDRpg27Zt6Ny5s6o9LCwMkyZNQtOmTTF16tRCjJDySxAEyGQy1eMKFSqgY8eOmD9/PkqXLl2IkZFYmZmZ0NPTA/CqiiWXy9GvXz8YGRlh1apVud5rKtrefL9OnDiBoUOH4tmzZ3B0dESZMmUwatQodO/evZCjpI8d/4STUK1atdCqVSssXLgQycnJqnYXFxdYWlri/PnzvHOmmMj5YZ4zdLh48WKsW7cOZ8+eLcyw6D3kJFrA6yrWgwcP0LRp08IKiQog599mZmYmjhw5gs6dOyMsLAybNm1C+fLl4e/vj+vXrxdylPSxY7IlMT8/P5w5cwabN29Wm+Nja2uL69ev8y/oYibn7qbu3bujQYMGmDt3LqKjowEAkZGRhRkavae7d+8iIiICtWrVAvDql3dmZmYhR0Vi6enpYdasWVi4cCEcHR3h7OyMAQMGICIiAllZWYUdHn3kmGxJzNnZGRMnTsTs2bOxadMmpKSkICkpCefPn0f//v0LOzx6Dzk/uFevXo3jx49j69atGDt2LDp37oxLly4VcnSUXzlV5dOnT8PY2Biurq4AgJkzZ2LMmDGqJJqKj5zlWHL+iH369CnMzc1hYWFRmGERcc7WhzJy5Ejs3r0btra2iIyMhJGREXbs2IEaNWoUdmhUAG5ubjh//jxsbW2xcuVKtGvXrrBDIpFGjRoFIyMjuLu7Y/jw4UhNTcWmTZvQtm3bwg6N3kPOnLxdu3ZhxowZ6NOnDyZPnlzYYdFHjsnWB/Ly5UvcuHEDFy9ehEKhYFWrmLtz5w48PT1x9+5d/PzzzxgyZEhhh0Tv4eXLl6hduzbu3LkDfX19zJw5ExMnTizssOg9xcXFYfbs2bh69SpCQkLw448/YtSoUYUdFhGXfvhQDAwMULduXdStW7ewQyEt0NHRQbdu3TBx4kSUKlWqsMOh92RgYAA7Ozu0adMGCxcuhIGBQWGHRAVgbm4OW1tbmJqaYu/evXw/qchgZYuIPmrZ2dnQ0dEp7DBIS7h0BxVFTLaIiIiIJMS7EYmIiIgkxGSLiIiISEJMtoiIiIgkxGSLiIiISEJMtoiIiIgkxGSLiIiISEJMtoiIiIgkxGSLiIiISEJMtoiIiIgkxGSLiIiISEL/ByE9OiwS+Ry/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Correlation Heatmap of Iris Dataset')\n",
    "a = sns.heatmap(corr_matrix, square=True, annot=True, fmt='.2f', linecolor='black')\n",
    "a.set_xticklabels(a.get_xticklabels(), rotation=30)\n",
    "a.set_yticklabels(a.get_yticklabels(), rotation=30)           \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.11757</td>\n",
       "      <td>0.871754</td>\n",
       "      <td>0.817941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.428440</td>\n",
       "      <td>-0.366126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0        1         2         3\n",
       "0 NaN -0.11757  0.871754  0.817941\n",
       "1 NaN      NaN -0.428440 -0.366126\n",
       "2 NaN      NaN       NaN  0.962865\n",
       "3 NaN      NaN       NaN       NaN"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "upper  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "# Find index of feature columns with correlation greater than 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2\n",
      "0    5.1  3.5  1.4\n",
      "1    4.9  3.0  1.4\n",
      "2    4.7  3.2  1.3\n",
      "3    4.6  3.1  1.5\n",
      "4    5.0  3.6  1.4\n",
      "..   ...  ...  ...\n",
      "145  6.7  3.0  5.2\n",
      "146  6.3  2.5  5.0\n",
      "147  6.5  3.0  5.2\n",
      "148  6.2  3.4  5.4\n",
      "149  5.9  3.0  5.1\n",
      "\n",
      "[150 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop Marked Features\n",
    "df1 = df.drop(df.columns[to_drop], axis=1)\n",
    "print(df1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
